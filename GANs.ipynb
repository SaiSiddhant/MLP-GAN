{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GANs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "df61065cc55148c4b5cc4fe797371514": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a0ccde3f4134404e9c45e144f9361be4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4f3f825ae85d4af8b9611d76863b3589",
              "IPY_MODEL_831e9638af664a688b004ec0abdc01fa"
            ]
          }
        },
        "a0ccde3f4134404e9c45e144f9361be4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4f3f825ae85d4af8b9611d76863b3589": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a5284689c4a8497280785d2f056fbf0a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1648877,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1648877,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_333ef167be344b278c8bde612261e081"
          }
        },
        "831e9638af664a688b004ec0abdc01fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7aa061d528d74610a8e7e72774c0406e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1649664/? [00:00&lt;00:00, 1796559.58it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fcb452ae6d264bdf9b7a2f1cf91de478"
          }
        },
        "a5284689c4a8497280785d2f056fbf0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "333ef167be344b278c8bde612261e081": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7aa061d528d74610a8e7e72774c0406e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fcb452ae6d264bdf9b7a2f1cf91de478": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ba617402ee294d03ae35f59248586930": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c72e0e6fb0d543748581af2d561cae05",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3eb6b397eafa408a94b06b9f065e19e1",
              "IPY_MODEL_550fd4f8c4e44d6db1b6b8a39e070a7b"
            ]
          }
        },
        "c72e0e6fb0d543748581af2d561cae05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3eb6b397eafa408a94b06b9f065e19e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6895ed66b2a94113b6f47b761fd2cfac",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4542,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4542,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_006c95f4b510457e99306e441f619a48"
          }
        },
        "550fd4f8c4e44d6db1b6b8a39e070a7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6f10a6200e474453a1aa0d4a5f6721c8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5120/? [11:01&lt;00:00,  7.74it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e7532d349f2340769469f9676b573d26"
          }
        },
        "6895ed66b2a94113b6f47b761fd2cfac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "006c95f4b510457e99306e441f619a48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f10a6200e474453a1aa0d4a5f6721c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e7532d349f2340769469f9676b573d26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QModtXN3aPGh"
      },
      "source": [
        "## MLP GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MkXEtERaMfi"
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vT5-9WA8aYMj"
      },
      "source": [
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Hyperparameters\n",
        "random_seed = 123\n",
        "generator_learning_rate = 0.001\n",
        "discriminator_learning_rate = 0.001\n",
        "num_epochs = 100\n",
        "batch_size = 128\n",
        "LATENT_DIM = 100\n",
        "IMG_SHAPE = (1, 28, 28)\n",
        "IMG_SIZE = 1\n",
        "for x in IMG_SHAPE:\n",
        "    IMG_SIZE *= x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655,
          "referenced_widgets": [
            "df61065cc55148c4b5cc4fe797371514",
            "a0ccde3f4134404e9c45e144f9361be4",
            "4f3f825ae85d4af8b9611d76863b3589",
            "831e9638af664a688b004ec0abdc01fa",
            "a5284689c4a8497280785d2f056fbf0a",
            "333ef167be344b278c8bde612261e081",
            "7aa061d528d74610a8e7e72774c0406e",
            "fcb452ae6d264bdf9b7a2f1cf91de478",
            "ba617402ee294d03ae35f59248586930",
            "c72e0e6fb0d543748581af2d561cae05",
            "3eb6b397eafa408a94b06b9f065e19e1",
            "550fd4f8c4e44d6db1b6b8a39e070a7b",
            "6895ed66b2a94113b6f47b761fd2cfac",
            "006c95f4b510457e99306e441f619a48",
            "6f10a6200e474453a1aa0d4a5f6721c8",
            "e7532d349f2340769469f9676b573d26"
          ]
        },
        "id": "auUzIXxcahkC",
        "outputId": "9636c204-ace9-42b8-9afc-d988b41568f5"
      },
      "source": [
        "train_dataset = datasets.MNIST(root='data', \n",
        "                               train=True, \n",
        "                               transform=transforms.ToTensor(),\n",
        "                               download=True)\n",
        "\n",
        "test_dataset = datasets.MNIST(root='data', \n",
        "                              train=False, \n",
        "                              transform=transforms.ToTensor())\n",
        "\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, \n",
        "                          batch_size=batch_size, \n",
        "                          shuffle=True)\n",
        "\n",
        "test_loader = DataLoader(dataset=test_dataset, \n",
        "                         batch_size=batch_size, \n",
        "                         shuffle=False)\n",
        "\n",
        "# Checking the dataset\n",
        "for images, labels in train_loader:  \n",
        "    print('Image batch dimensions:', images.shape)\n",
        "    print('Image label dimensions:', labels.shape)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Using downloaded and verified file: data/MNIST/raw/train-images-idx3-ubyte.gz\n",
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Using downloaded and verified file: data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df61065cc55148c4b5cc4fe797371514",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1648877.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba617402ee294d03ae35f59248586930",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4542.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Image batch dimensions: torch.Size([128, 1, 28, 28])\n",
            "Image label dimensions: torch.Size([128])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoReOeeuanpo"
      },
      "source": [
        "class GAN(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(GAN, self).__init__()\n",
        "        \n",
        "        \n",
        "        self.generator = nn.Sequential(\n",
        "            nn.Linear(LATENT_DIM, 128),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(128, IMG_SIZE),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "        \n",
        "        self.discriminator = nn.Sequential(\n",
        "            nn.Linear(IMG_SIZE, 128),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "            \n",
        "    def generator_forward(self, z):\n",
        "        img = self.generator(z)\n",
        "        return img\n",
        "    \n",
        "    def discriminator_forward(self, img):\n",
        "        pred = model.discriminator(img)\n",
        "        return pred.view(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDkdFSPJa83p"
      },
      "source": [
        "torch.manual_seed(random_seed)\n",
        "\n",
        "model = GAN()\n",
        "model = model.to(device)\n",
        "\n",
        "optim_gener = torch.optim.Adam(model.generator.parameters(), lr=generator_learning_rate)\n",
        "optim_discr = torch.optim.Adam(model.discriminator.parameters(), lr=discriminator_learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7V3JfgNpbAK3",
        "outputId": "11cfada7-51c9-43da-c359-308bc5f58b75"
      },
      "source": [
        "start_time = time.time()    \n",
        "\n",
        "discr_costs = []\n",
        "gener_costs = []\n",
        "for epoch in range(num_epochs):\n",
        "    model = model.train()\n",
        "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
        "\n",
        "        \n",
        "        \n",
        "        features = (features - 0.5)*2.\n",
        "        features = features.view(-1, IMG_SIZE).to(device) \n",
        "        targets = targets.to(device)\n",
        "\n",
        "        valid = torch.ones(targets.size(0)).float().to(device)\n",
        "        fake = torch.zeros(targets.size(0)).float().to(device)\n",
        "        \n",
        "\n",
        "        ### FORWARD AND BACK PROP\n",
        "        \n",
        "        \n",
        "        # --------------------------\n",
        "        # Train Generator\n",
        "        # --------------------------\n",
        "        \n",
        "        # Make new images\n",
        "        z = torch.zeros((targets.size(0), LATENT_DIM)).uniform_(-1.0, 1.0).to(device)\n",
        "        generated_features = model.generator_forward(z)\n",
        "        \n",
        "        # Loss for fooling the discriminator\n",
        "        discr_pred = model.discriminator_forward(generated_features)\n",
        "        \n",
        "        gener_loss = F.binary_cross_entropy(discr_pred, valid)\n",
        "        \n",
        "        optim_gener.zero_grad()\n",
        "        gener_loss.backward()\n",
        "        optim_gener.step()\n",
        "        \n",
        "        # --------------------------\n",
        "        # Train Discriminator\n",
        "        # --------------------------        \n",
        "        \n",
        "        discr_pred_real = model.discriminator_forward(features.view(-1, IMG_SIZE))\n",
        "        real_loss = F.binary_cross_entropy(discr_pred_real, valid)\n",
        "        \n",
        "        discr_pred_fake = model.discriminator_forward(generated_features.detach())\n",
        "        fake_loss = F.binary_cross_entropy(discr_pred_fake, fake)\n",
        "        \n",
        "        discr_loss = 0.5*(real_loss + fake_loss)\n",
        "\n",
        "        optim_discr.zero_grad()\n",
        "        discr_loss.backward()\n",
        "        optim_discr.step()        \n",
        "        \n",
        "        discr_costs.append(discr_loss.item())\n",
        "        gener_costs.append(gener_loss.item())\n",
        "        \n",
        "        \n",
        "        ### LOGGING\n",
        "        if not batch_idx % 100:\n",
        "            print ('Epoch: %03d/%03d | Batch %03d/%03d | Gen/Dis Loss: %.4f/%.4f' \n",
        "                   %(epoch+1, num_epochs, batch_idx, \n",
        "                     len(train_loader), gener_loss, discr_loss))\n",
        "\n",
        "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
        "    \n",
        "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 001/100 | Batch 000/469 | Gen/Dis Loss: 0.6817/0.7123\n",
            "Epoch: 001/100 | Batch 100/469 | Gen/Dis Loss: 4.6622/0.0372\n",
            "Epoch: 001/100 | Batch 200/469 | Gen/Dis Loss: 1.6639/0.1155\n",
            "Epoch: 001/100 | Batch 300/469 | Gen/Dis Loss: 1.8117/0.1363\n",
            "Epoch: 001/100 | Batch 400/469 | Gen/Dis Loss: 1.1614/0.3296\n",
            "Time elapsed: 0.11 min\n",
            "Epoch: 002/100 | Batch 000/469 | Gen/Dis Loss: 2.8025/0.1087\n",
            "Epoch: 002/100 | Batch 100/469 | Gen/Dis Loss: 2.0865/0.2676\n",
            "Epoch: 002/100 | Batch 200/469 | Gen/Dis Loss: 1.0121/0.4386\n",
            "Epoch: 002/100 | Batch 300/469 | Gen/Dis Loss: 1.0596/0.4183\n",
            "Epoch: 002/100 | Batch 400/469 | Gen/Dis Loss: 0.5681/0.5841\n",
            "Time elapsed: 0.22 min\n",
            "Epoch: 003/100 | Batch 000/469 | Gen/Dis Loss: 0.6606/0.5623\n",
            "Epoch: 003/100 | Batch 100/469 | Gen/Dis Loss: 0.6817/0.5219\n",
            "Epoch: 003/100 | Batch 200/469 | Gen/Dis Loss: 1.3522/0.4011\n",
            "Epoch: 003/100 | Batch 300/469 | Gen/Dis Loss: 1.2498/0.4364\n",
            "Epoch: 003/100 | Batch 400/469 | Gen/Dis Loss: 2.5578/0.3757\n",
            "Time elapsed: 0.33 min\n",
            "Epoch: 004/100 | Batch 000/469 | Gen/Dis Loss: 1.3385/0.4568\n",
            "Epoch: 004/100 | Batch 100/469 | Gen/Dis Loss: 1.0527/0.4319\n",
            "Epoch: 004/100 | Batch 200/469 | Gen/Dis Loss: 0.7404/0.5873\n",
            "Epoch: 004/100 | Batch 300/469 | Gen/Dis Loss: 0.8106/0.5245\n",
            "Epoch: 004/100 | Batch 400/469 | Gen/Dis Loss: 0.9919/0.5420\n",
            "Time elapsed: 0.44 min\n",
            "Epoch: 005/100 | Batch 000/469 | Gen/Dis Loss: 0.9160/0.5386\n",
            "Epoch: 005/100 | Batch 100/469 | Gen/Dis Loss: 0.9000/0.6064\n",
            "Epoch: 005/100 | Batch 200/469 | Gen/Dis Loss: 1.2389/0.4824\n",
            "Epoch: 005/100 | Batch 300/469 | Gen/Dis Loss: 1.1731/0.4427\n",
            "Epoch: 005/100 | Batch 400/469 | Gen/Dis Loss: 1.0192/0.4655\n",
            "Time elapsed: 0.55 min\n",
            "Epoch: 006/100 | Batch 000/469 | Gen/Dis Loss: 1.2363/0.4749\n",
            "Epoch: 006/100 | Batch 100/469 | Gen/Dis Loss: 0.8841/0.4663\n",
            "Epoch: 006/100 | Batch 200/469 | Gen/Dis Loss: 1.1773/0.4745\n",
            "Epoch: 006/100 | Batch 300/469 | Gen/Dis Loss: 1.3658/0.3861\n",
            "Epoch: 006/100 | Batch 400/469 | Gen/Dis Loss: 1.3830/0.4838\n",
            "Time elapsed: 0.66 min\n",
            "Epoch: 007/100 | Batch 000/469 | Gen/Dis Loss: 1.0811/0.5550\n",
            "Epoch: 007/100 | Batch 100/469 | Gen/Dis Loss: 1.8272/0.4135\n",
            "Epoch: 007/100 | Batch 200/469 | Gen/Dis Loss: 1.2128/0.5000\n",
            "Epoch: 007/100 | Batch 300/469 | Gen/Dis Loss: 0.9254/0.5053\n",
            "Epoch: 007/100 | Batch 400/469 | Gen/Dis Loss: 1.5408/0.3924\n",
            "Time elapsed: 0.77 min\n",
            "Epoch: 008/100 | Batch 000/469 | Gen/Dis Loss: 1.3384/0.4984\n",
            "Epoch: 008/100 | Batch 100/469 | Gen/Dis Loss: 0.8515/0.6271\n",
            "Epoch: 008/100 | Batch 200/469 | Gen/Dis Loss: 0.9245/0.5315\n",
            "Epoch: 008/100 | Batch 300/469 | Gen/Dis Loss: 1.4073/0.4920\n",
            "Epoch: 008/100 | Batch 400/469 | Gen/Dis Loss: 2.3565/0.4178\n",
            "Time elapsed: 0.88 min\n",
            "Epoch: 009/100 | Batch 000/469 | Gen/Dis Loss: 1.0226/0.5252\n",
            "Epoch: 009/100 | Batch 100/469 | Gen/Dis Loss: 1.0242/0.4543\n",
            "Epoch: 009/100 | Batch 200/469 | Gen/Dis Loss: 1.2271/0.4914\n",
            "Epoch: 009/100 | Batch 300/469 | Gen/Dis Loss: 1.6175/0.5207\n",
            "Epoch: 009/100 | Batch 400/469 | Gen/Dis Loss: 1.2225/0.4794\n",
            "Time elapsed: 0.98 min\n",
            "Epoch: 010/100 | Batch 000/469 | Gen/Dis Loss: 1.1696/0.4856\n",
            "Epoch: 010/100 | Batch 100/469 | Gen/Dis Loss: 1.4111/0.4760\n",
            "Epoch: 010/100 | Batch 200/469 | Gen/Dis Loss: 1.6005/0.5703\n",
            "Epoch: 010/100 | Batch 300/469 | Gen/Dis Loss: 1.0273/0.5611\n",
            "Epoch: 010/100 | Batch 400/469 | Gen/Dis Loss: 1.2072/0.5074\n",
            "Time elapsed: 1.09 min\n",
            "Epoch: 011/100 | Batch 000/469 | Gen/Dis Loss: 1.2142/0.5694\n",
            "Epoch: 011/100 | Batch 100/469 | Gen/Dis Loss: 1.0000/0.5512\n",
            "Epoch: 011/100 | Batch 200/469 | Gen/Dis Loss: 1.2570/0.5791\n",
            "Epoch: 011/100 | Batch 300/469 | Gen/Dis Loss: 0.9832/0.4951\n",
            "Epoch: 011/100 | Batch 400/469 | Gen/Dis Loss: 1.3356/0.5660\n",
            "Time elapsed: 1.20 min\n",
            "Epoch: 012/100 | Batch 000/469 | Gen/Dis Loss: 0.9214/0.5257\n",
            "Epoch: 012/100 | Batch 100/469 | Gen/Dis Loss: 1.4742/0.5165\n",
            "Epoch: 012/100 | Batch 200/469 | Gen/Dis Loss: 1.1836/0.5413\n",
            "Epoch: 012/100 | Batch 300/469 | Gen/Dis Loss: 1.2620/0.5202\n",
            "Epoch: 012/100 | Batch 400/469 | Gen/Dis Loss: 1.3362/0.4585\n",
            "Time elapsed: 1.30 min\n",
            "Epoch: 013/100 | Batch 000/469 | Gen/Dis Loss: 1.3269/0.5275\n",
            "Epoch: 013/100 | Batch 100/469 | Gen/Dis Loss: 1.3453/0.5127\n",
            "Epoch: 013/100 | Batch 200/469 | Gen/Dis Loss: 0.9003/0.5640\n",
            "Epoch: 013/100 | Batch 300/469 | Gen/Dis Loss: 1.1644/0.5733\n",
            "Epoch: 013/100 | Batch 400/469 | Gen/Dis Loss: 1.1576/0.5525\n",
            "Time elapsed: 1.41 min\n",
            "Epoch: 014/100 | Batch 000/469 | Gen/Dis Loss: 1.3170/0.5066\n",
            "Epoch: 014/100 | Batch 100/469 | Gen/Dis Loss: 1.0529/0.5534\n",
            "Epoch: 014/100 | Batch 200/469 | Gen/Dis Loss: 1.3952/0.4715\n",
            "Epoch: 014/100 | Batch 300/469 | Gen/Dis Loss: 1.6020/0.5523\n",
            "Epoch: 014/100 | Batch 400/469 | Gen/Dis Loss: 1.2490/0.5343\n",
            "Time elapsed: 1.51 min\n",
            "Epoch: 015/100 | Batch 000/469 | Gen/Dis Loss: 1.7719/0.5059\n",
            "Epoch: 015/100 | Batch 100/469 | Gen/Dis Loss: 1.2039/0.5023\n",
            "Epoch: 015/100 | Batch 200/469 | Gen/Dis Loss: 1.2462/0.5067\n",
            "Epoch: 015/100 | Batch 300/469 | Gen/Dis Loss: 1.1106/0.6391\n",
            "Epoch: 015/100 | Batch 400/469 | Gen/Dis Loss: 1.0928/0.5647\n",
            "Time elapsed: 1.61 min\n",
            "Epoch: 016/100 | Batch 000/469 | Gen/Dis Loss: 1.3018/0.5763\n",
            "Epoch: 016/100 | Batch 100/469 | Gen/Dis Loss: 1.1347/0.5620\n",
            "Epoch: 016/100 | Batch 200/469 | Gen/Dis Loss: 1.0651/0.5590\n",
            "Epoch: 016/100 | Batch 300/469 | Gen/Dis Loss: 0.9579/0.6071\n",
            "Epoch: 016/100 | Batch 400/469 | Gen/Dis Loss: 1.0183/0.5722\n",
            "Time elapsed: 1.71 min\n",
            "Epoch: 017/100 | Batch 000/469 | Gen/Dis Loss: 1.1545/0.6007\n",
            "Epoch: 017/100 | Batch 100/469 | Gen/Dis Loss: 0.9734/0.5845\n",
            "Epoch: 017/100 | Batch 200/469 | Gen/Dis Loss: 1.4322/0.5730\n",
            "Epoch: 017/100 | Batch 300/469 | Gen/Dis Loss: 0.8675/0.6096\n",
            "Epoch: 017/100 | Batch 400/469 | Gen/Dis Loss: 0.9327/0.5731\n",
            "Time elapsed: 1.82 min\n",
            "Epoch: 018/100 | Batch 000/469 | Gen/Dis Loss: 0.7837/0.6026\n",
            "Epoch: 018/100 | Batch 100/469 | Gen/Dis Loss: 1.3059/0.5703\n",
            "Epoch: 018/100 | Batch 200/469 | Gen/Dis Loss: 1.0077/0.5103\n",
            "Epoch: 018/100 | Batch 300/469 | Gen/Dis Loss: 1.2912/0.5700\n",
            "Epoch: 018/100 | Batch 400/469 | Gen/Dis Loss: 1.0179/0.5211\n",
            "Time elapsed: 1.93 min\n",
            "Epoch: 019/100 | Batch 000/469 | Gen/Dis Loss: 0.9379/0.5385\n",
            "Epoch: 019/100 | Batch 100/469 | Gen/Dis Loss: 1.2085/0.4918\n",
            "Epoch: 019/100 | Batch 200/469 | Gen/Dis Loss: 1.0146/0.5977\n",
            "Epoch: 019/100 | Batch 300/469 | Gen/Dis Loss: 0.9347/0.5613\n",
            "Epoch: 019/100 | Batch 400/469 | Gen/Dis Loss: 1.7069/0.4312\n",
            "Time elapsed: 2.04 min\n",
            "Epoch: 020/100 | Batch 000/469 | Gen/Dis Loss: 1.4193/0.5443\n",
            "Epoch: 020/100 | Batch 100/469 | Gen/Dis Loss: 1.1317/0.5155\n",
            "Epoch: 020/100 | Batch 200/469 | Gen/Dis Loss: 1.2943/0.5553\n",
            "Epoch: 020/100 | Batch 300/469 | Gen/Dis Loss: 0.9921/0.4969\n",
            "Epoch: 020/100 | Batch 400/469 | Gen/Dis Loss: 1.0079/0.5381\n",
            "Time elapsed: 2.15 min\n",
            "Epoch: 021/100 | Batch 000/469 | Gen/Dis Loss: 1.0564/0.5935\n",
            "Epoch: 021/100 | Batch 100/469 | Gen/Dis Loss: 0.9337/0.5771\n",
            "Epoch: 021/100 | Batch 200/469 | Gen/Dis Loss: 0.9486/0.5586\n",
            "Epoch: 021/100 | Batch 300/469 | Gen/Dis Loss: 1.3934/0.5832\n",
            "Epoch: 021/100 | Batch 400/469 | Gen/Dis Loss: 1.0486/0.5961\n",
            "Time elapsed: 2.26 min\n",
            "Epoch: 022/100 | Batch 000/469 | Gen/Dis Loss: 1.0046/0.6188\n",
            "Epoch: 022/100 | Batch 100/469 | Gen/Dis Loss: 1.4484/0.6327\n",
            "Epoch: 022/100 | Batch 200/469 | Gen/Dis Loss: 0.8655/0.6295\n",
            "Epoch: 022/100 | Batch 300/469 | Gen/Dis Loss: 0.9965/0.5152\n",
            "Epoch: 022/100 | Batch 400/469 | Gen/Dis Loss: 0.9029/0.5704\n",
            "Time elapsed: 2.37 min\n",
            "Epoch: 023/100 | Batch 000/469 | Gen/Dis Loss: 1.1763/0.5937\n",
            "Epoch: 023/100 | Batch 100/469 | Gen/Dis Loss: 1.1288/0.5921\n",
            "Epoch: 023/100 | Batch 200/469 | Gen/Dis Loss: 1.2223/0.5393\n",
            "Epoch: 023/100 | Batch 300/469 | Gen/Dis Loss: 1.7849/0.4692\n",
            "Epoch: 023/100 | Batch 400/469 | Gen/Dis Loss: 1.0606/0.5761\n",
            "Time elapsed: 2.48 min\n",
            "Epoch: 024/100 | Batch 000/469 | Gen/Dis Loss: 1.0981/0.5216\n",
            "Epoch: 024/100 | Batch 100/469 | Gen/Dis Loss: 1.2991/0.5342\n",
            "Epoch: 024/100 | Batch 200/469 | Gen/Dis Loss: 1.5056/0.5094\n",
            "Epoch: 024/100 | Batch 300/469 | Gen/Dis Loss: 1.3643/0.5004\n",
            "Epoch: 024/100 | Batch 400/469 | Gen/Dis Loss: 0.9280/0.5859\n",
            "Time elapsed: 2.59 min\n",
            "Epoch: 025/100 | Batch 000/469 | Gen/Dis Loss: 0.8620/0.5950\n",
            "Epoch: 025/100 | Batch 100/469 | Gen/Dis Loss: 0.9781/0.5932\n",
            "Epoch: 025/100 | Batch 200/469 | Gen/Dis Loss: 1.0871/0.5162\n",
            "Epoch: 025/100 | Batch 300/469 | Gen/Dis Loss: 0.9517/0.5845\n",
            "Epoch: 025/100 | Batch 400/469 | Gen/Dis Loss: 0.9479/0.5704\n",
            "Time elapsed: 2.70 min\n",
            "Epoch: 026/100 | Batch 000/469 | Gen/Dis Loss: 1.0731/0.5802\n",
            "Epoch: 026/100 | Batch 100/469 | Gen/Dis Loss: 1.0495/0.5572\n",
            "Epoch: 026/100 | Batch 200/469 | Gen/Dis Loss: 0.8144/0.6059\n",
            "Epoch: 026/100 | Batch 300/469 | Gen/Dis Loss: 1.0168/0.6205\n",
            "Epoch: 026/100 | Batch 400/469 | Gen/Dis Loss: 1.2013/0.5583\n",
            "Time elapsed: 2.81 min\n",
            "Epoch: 027/100 | Batch 000/469 | Gen/Dis Loss: 1.3431/0.5839\n",
            "Epoch: 027/100 | Batch 100/469 | Gen/Dis Loss: 1.2050/0.6003\n",
            "Epoch: 027/100 | Batch 200/469 | Gen/Dis Loss: 0.8958/0.5980\n",
            "Epoch: 027/100 | Batch 300/469 | Gen/Dis Loss: 0.9024/0.6388\n",
            "Epoch: 027/100 | Batch 400/469 | Gen/Dis Loss: 0.8231/0.6021\n",
            "Time elapsed: 2.92 min\n",
            "Epoch: 028/100 | Batch 000/469 | Gen/Dis Loss: 1.0926/0.5362\n",
            "Epoch: 028/100 | Batch 100/469 | Gen/Dis Loss: 0.8097/0.6007\n",
            "Epoch: 028/100 | Batch 200/469 | Gen/Dis Loss: 0.9972/0.6026\n",
            "Epoch: 028/100 | Batch 300/469 | Gen/Dis Loss: 1.1560/0.5693\n",
            "Epoch: 028/100 | Batch 400/469 | Gen/Dis Loss: 0.9045/0.5997\n",
            "Time elapsed: 3.03 min\n",
            "Epoch: 029/100 | Batch 000/469 | Gen/Dis Loss: 1.1479/0.6023\n",
            "Epoch: 029/100 | Batch 100/469 | Gen/Dis Loss: 1.0391/0.5661\n",
            "Epoch: 029/100 | Batch 200/469 | Gen/Dis Loss: 0.9353/0.5943\n",
            "Epoch: 029/100 | Batch 300/469 | Gen/Dis Loss: 1.1131/0.6002\n",
            "Epoch: 029/100 | Batch 400/469 | Gen/Dis Loss: 1.1849/0.5970\n",
            "Time elapsed: 3.14 min\n",
            "Epoch: 030/100 | Batch 000/469 | Gen/Dis Loss: 0.9001/0.6143\n",
            "Epoch: 030/100 | Batch 100/469 | Gen/Dis Loss: 0.9741/0.5682\n",
            "Epoch: 030/100 | Batch 200/469 | Gen/Dis Loss: 1.2044/0.5588\n",
            "Epoch: 030/100 | Batch 300/469 | Gen/Dis Loss: 0.8722/0.6071\n",
            "Epoch: 030/100 | Batch 400/469 | Gen/Dis Loss: 1.0170/0.6473\n",
            "Time elapsed: 3.25 min\n",
            "Epoch: 031/100 | Batch 000/469 | Gen/Dis Loss: 1.3655/0.6396\n",
            "Epoch: 031/100 | Batch 100/469 | Gen/Dis Loss: 0.9023/0.6249\n",
            "Epoch: 031/100 | Batch 200/469 | Gen/Dis Loss: 0.9540/0.5608\n",
            "Epoch: 031/100 | Batch 300/469 | Gen/Dis Loss: 0.9724/0.6032\n",
            "Epoch: 031/100 | Batch 400/469 | Gen/Dis Loss: 0.9268/0.6088\n",
            "Time elapsed: 3.36 min\n",
            "Epoch: 032/100 | Batch 000/469 | Gen/Dis Loss: 0.9156/0.6008\n",
            "Epoch: 032/100 | Batch 100/469 | Gen/Dis Loss: 0.9429/0.5809\n",
            "Epoch: 032/100 | Batch 200/469 | Gen/Dis Loss: 0.9265/0.5762\n",
            "Epoch: 032/100 | Batch 300/469 | Gen/Dis Loss: 0.8815/0.6123\n",
            "Epoch: 032/100 | Batch 400/469 | Gen/Dis Loss: 1.1074/0.5906\n",
            "Time elapsed: 3.47 min\n",
            "Epoch: 033/100 | Batch 000/469 | Gen/Dis Loss: 0.9002/0.5498\n",
            "Epoch: 033/100 | Batch 100/469 | Gen/Dis Loss: 0.9791/0.6173\n",
            "Epoch: 033/100 | Batch 200/469 | Gen/Dis Loss: 0.9682/0.5899\n",
            "Epoch: 033/100 | Batch 300/469 | Gen/Dis Loss: 1.0116/0.6346\n",
            "Epoch: 033/100 | Batch 400/469 | Gen/Dis Loss: 1.1100/0.5262\n",
            "Time elapsed: 3.58 min\n",
            "Epoch: 034/100 | Batch 000/469 | Gen/Dis Loss: 1.0142/0.5871\n",
            "Epoch: 034/100 | Batch 100/469 | Gen/Dis Loss: 1.2535/0.5468\n",
            "Epoch: 034/100 | Batch 200/469 | Gen/Dis Loss: 1.1727/0.5833\n",
            "Epoch: 034/100 | Batch 300/469 | Gen/Dis Loss: 0.7961/0.5746\n",
            "Epoch: 034/100 | Batch 400/469 | Gen/Dis Loss: 0.9415/0.6314\n",
            "Time elapsed: 3.69 min\n",
            "Epoch: 035/100 | Batch 000/469 | Gen/Dis Loss: 0.9818/0.6158\n",
            "Epoch: 035/100 | Batch 100/469 | Gen/Dis Loss: 0.7655/0.6303\n",
            "Epoch: 035/100 | Batch 200/469 | Gen/Dis Loss: 1.1224/0.6079\n",
            "Epoch: 035/100 | Batch 300/469 | Gen/Dis Loss: 0.9578/0.5449\n",
            "Epoch: 035/100 | Batch 400/469 | Gen/Dis Loss: 0.9094/0.5682\n",
            "Time elapsed: 3.80 min\n",
            "Epoch: 036/100 | Batch 000/469 | Gen/Dis Loss: 0.8906/0.6402\n",
            "Epoch: 036/100 | Batch 100/469 | Gen/Dis Loss: 1.0745/0.6073\n",
            "Epoch: 036/100 | Batch 200/469 | Gen/Dis Loss: 0.9713/0.6173\n",
            "Epoch: 036/100 | Batch 300/469 | Gen/Dis Loss: 1.0442/0.6131\n",
            "Epoch: 036/100 | Batch 400/469 | Gen/Dis Loss: 0.9243/0.5808\n",
            "Time elapsed: 3.91 min\n",
            "Epoch: 037/100 | Batch 000/469 | Gen/Dis Loss: 0.8973/0.5946\n",
            "Epoch: 037/100 | Batch 100/469 | Gen/Dis Loss: 1.1047/0.6008\n",
            "Epoch: 037/100 | Batch 200/469 | Gen/Dis Loss: 1.2199/0.6203\n",
            "Epoch: 037/100 | Batch 300/469 | Gen/Dis Loss: 0.8537/0.6549\n",
            "Epoch: 037/100 | Batch 400/469 | Gen/Dis Loss: 0.9681/0.6273\n",
            "Time elapsed: 4.02 min\n",
            "Epoch: 038/100 | Batch 000/469 | Gen/Dis Loss: 0.9401/0.5869\n",
            "Epoch: 038/100 | Batch 100/469 | Gen/Dis Loss: 0.8867/0.5694\n",
            "Epoch: 038/100 | Batch 200/469 | Gen/Dis Loss: 0.8619/0.6029\n",
            "Epoch: 038/100 | Batch 300/469 | Gen/Dis Loss: 0.9570/0.6436\n",
            "Epoch: 038/100 | Batch 400/469 | Gen/Dis Loss: 0.9622/0.5918\n",
            "Time elapsed: 4.13 min\n",
            "Epoch: 039/100 | Batch 000/469 | Gen/Dis Loss: 0.9674/0.5824\n",
            "Epoch: 039/100 | Batch 100/469 | Gen/Dis Loss: 0.8636/0.6157\n",
            "Epoch: 039/100 | Batch 200/469 | Gen/Dis Loss: 0.9007/0.6126\n",
            "Epoch: 039/100 | Batch 300/469 | Gen/Dis Loss: 0.9698/0.6062\n",
            "Epoch: 039/100 | Batch 400/469 | Gen/Dis Loss: 0.8576/0.5892\n",
            "Time elapsed: 4.24 min\n",
            "Epoch: 040/100 | Batch 000/469 | Gen/Dis Loss: 0.9319/0.6063\n",
            "Epoch: 040/100 | Batch 100/469 | Gen/Dis Loss: 0.8911/0.6419\n",
            "Epoch: 040/100 | Batch 200/469 | Gen/Dis Loss: 0.9985/0.5733\n",
            "Epoch: 040/100 | Batch 300/469 | Gen/Dis Loss: 0.8190/0.6563\n",
            "Epoch: 040/100 | Batch 400/469 | Gen/Dis Loss: 0.9037/0.6038\n",
            "Time elapsed: 4.35 min\n",
            "Epoch: 041/100 | Batch 000/469 | Gen/Dis Loss: 0.9234/0.5781\n",
            "Epoch: 041/100 | Batch 100/469 | Gen/Dis Loss: 1.2283/0.5860\n",
            "Epoch: 041/100 | Batch 200/469 | Gen/Dis Loss: 0.8362/0.5931\n",
            "Epoch: 041/100 | Batch 300/469 | Gen/Dis Loss: 0.8292/0.6042\n",
            "Epoch: 041/100 | Batch 400/469 | Gen/Dis Loss: 0.8805/0.6276\n",
            "Time elapsed: 4.46 min\n",
            "Epoch: 042/100 | Batch 000/469 | Gen/Dis Loss: 0.8329/0.5979\n",
            "Epoch: 042/100 | Batch 100/469 | Gen/Dis Loss: 1.0319/0.6039\n",
            "Epoch: 042/100 | Batch 200/469 | Gen/Dis Loss: 0.9031/0.6263\n",
            "Epoch: 042/100 | Batch 300/469 | Gen/Dis Loss: 0.9626/0.6266\n",
            "Epoch: 042/100 | Batch 400/469 | Gen/Dis Loss: 0.9615/0.6429\n",
            "Time elapsed: 4.57 min\n",
            "Epoch: 043/100 | Batch 000/469 | Gen/Dis Loss: 1.1475/0.5857\n",
            "Epoch: 043/100 | Batch 100/469 | Gen/Dis Loss: 1.1952/0.6040\n",
            "Epoch: 043/100 | Batch 200/469 | Gen/Dis Loss: 1.0990/0.5873\n",
            "Epoch: 043/100 | Batch 300/469 | Gen/Dis Loss: 1.0743/0.6497\n",
            "Epoch: 043/100 | Batch 400/469 | Gen/Dis Loss: 1.0397/0.6209\n",
            "Time elapsed: 4.68 min\n",
            "Epoch: 044/100 | Batch 000/469 | Gen/Dis Loss: 0.9838/0.6151\n",
            "Epoch: 044/100 | Batch 100/469 | Gen/Dis Loss: 0.9038/0.6229\n",
            "Epoch: 044/100 | Batch 200/469 | Gen/Dis Loss: 1.0039/0.6247\n",
            "Epoch: 044/100 | Batch 300/469 | Gen/Dis Loss: 0.9360/0.5971\n",
            "Epoch: 044/100 | Batch 400/469 | Gen/Dis Loss: 0.8718/0.6161\n",
            "Time elapsed: 4.78 min\n",
            "Epoch: 045/100 | Batch 000/469 | Gen/Dis Loss: 0.9336/0.5988\n",
            "Epoch: 045/100 | Batch 100/469 | Gen/Dis Loss: 1.2585/0.5972\n",
            "Epoch: 045/100 | Batch 200/469 | Gen/Dis Loss: 0.9764/0.5949\n",
            "Epoch: 045/100 | Batch 300/469 | Gen/Dis Loss: 0.9162/0.6440\n",
            "Epoch: 045/100 | Batch 400/469 | Gen/Dis Loss: 1.0433/0.5765\n",
            "Time elapsed: 4.89 min\n",
            "Epoch: 046/100 | Batch 000/469 | Gen/Dis Loss: 0.8763/0.5898\n",
            "Epoch: 046/100 | Batch 100/469 | Gen/Dis Loss: 0.8813/0.6302\n",
            "Epoch: 046/100 | Batch 200/469 | Gen/Dis Loss: 0.8833/0.6329\n",
            "Epoch: 046/100 | Batch 300/469 | Gen/Dis Loss: 1.1773/0.6033\n",
            "Epoch: 046/100 | Batch 400/469 | Gen/Dis Loss: 0.8409/0.6281\n",
            "Time elapsed: 5.00 min\n",
            "Epoch: 047/100 | Batch 000/469 | Gen/Dis Loss: 0.8807/0.6207\n",
            "Epoch: 047/100 | Batch 100/469 | Gen/Dis Loss: 0.8726/0.6014\n",
            "Epoch: 047/100 | Batch 200/469 | Gen/Dis Loss: 0.8583/0.6426\n",
            "Epoch: 047/100 | Batch 300/469 | Gen/Dis Loss: 0.9344/0.6189\n",
            "Epoch: 047/100 | Batch 400/469 | Gen/Dis Loss: 0.8325/0.6801\n",
            "Time elapsed: 5.11 min\n",
            "Epoch: 048/100 | Batch 000/469 | Gen/Dis Loss: 0.8128/0.5995\n",
            "Epoch: 048/100 | Batch 100/469 | Gen/Dis Loss: 1.0659/0.5856\n",
            "Epoch: 048/100 | Batch 200/469 | Gen/Dis Loss: 0.8657/0.6271\n",
            "Epoch: 048/100 | Batch 300/469 | Gen/Dis Loss: 0.8054/0.6609\n",
            "Epoch: 048/100 | Batch 400/469 | Gen/Dis Loss: 0.9115/0.6388\n",
            "Time elapsed: 5.22 min\n",
            "Epoch: 049/100 | Batch 000/469 | Gen/Dis Loss: 0.8747/0.6220\n",
            "Epoch: 049/100 | Batch 100/469 | Gen/Dis Loss: 1.0553/0.6030\n",
            "Epoch: 049/100 | Batch 200/469 | Gen/Dis Loss: 0.9388/0.6311\n",
            "Epoch: 049/100 | Batch 300/469 | Gen/Dis Loss: 0.9822/0.5936\n",
            "Epoch: 049/100 | Batch 400/469 | Gen/Dis Loss: 0.9122/0.5965\n",
            "Time elapsed: 5.33 min\n",
            "Epoch: 050/100 | Batch 000/469 | Gen/Dis Loss: 0.9387/0.5822\n",
            "Epoch: 050/100 | Batch 100/469 | Gen/Dis Loss: 0.9827/0.6345\n",
            "Epoch: 050/100 | Batch 200/469 | Gen/Dis Loss: 0.9164/0.6448\n",
            "Epoch: 050/100 | Batch 300/469 | Gen/Dis Loss: 1.2286/0.5927\n",
            "Epoch: 050/100 | Batch 400/469 | Gen/Dis Loss: 0.9045/0.6108\n",
            "Time elapsed: 5.43 min\n",
            "Epoch: 051/100 | Batch 000/469 | Gen/Dis Loss: 0.8261/0.6494\n",
            "Epoch: 051/100 | Batch 100/469 | Gen/Dis Loss: 1.0128/0.6215\n",
            "Epoch: 051/100 | Batch 200/469 | Gen/Dis Loss: 0.8906/0.6046\n",
            "Epoch: 051/100 | Batch 300/469 | Gen/Dis Loss: 0.8894/0.6353\n",
            "Epoch: 051/100 | Batch 400/469 | Gen/Dis Loss: 1.0352/0.6367\n",
            "Time elapsed: 5.54 min\n",
            "Epoch: 052/100 | Batch 000/469 | Gen/Dis Loss: 1.1732/0.6037\n",
            "Epoch: 052/100 | Batch 100/469 | Gen/Dis Loss: 0.9242/0.6409\n",
            "Epoch: 052/100 | Batch 200/469 | Gen/Dis Loss: 0.8700/0.6136\n",
            "Epoch: 052/100 | Batch 300/469 | Gen/Dis Loss: 0.9023/0.6251\n",
            "Epoch: 052/100 | Batch 400/469 | Gen/Dis Loss: 0.8273/0.6140\n",
            "Time elapsed: 5.65 min\n",
            "Epoch: 053/100 | Batch 000/469 | Gen/Dis Loss: 0.8491/0.6194\n",
            "Epoch: 053/100 | Batch 100/469 | Gen/Dis Loss: 0.9942/0.6385\n",
            "Epoch: 053/100 | Batch 200/469 | Gen/Dis Loss: 0.8098/0.6229\n",
            "Epoch: 053/100 | Batch 300/469 | Gen/Dis Loss: 0.8760/0.5876\n",
            "Epoch: 053/100 | Batch 400/469 | Gen/Dis Loss: 0.9679/0.5829\n",
            "Time elapsed: 5.75 min\n",
            "Epoch: 054/100 | Batch 000/469 | Gen/Dis Loss: 0.9120/0.6073\n",
            "Epoch: 054/100 | Batch 100/469 | Gen/Dis Loss: 0.9393/0.6217\n",
            "Epoch: 054/100 | Batch 200/469 | Gen/Dis Loss: 0.8484/0.6344\n",
            "Epoch: 054/100 | Batch 300/469 | Gen/Dis Loss: 0.8355/0.6102\n",
            "Epoch: 054/100 | Batch 400/469 | Gen/Dis Loss: 0.9427/0.6016\n",
            "Time elapsed: 5.86 min\n",
            "Epoch: 055/100 | Batch 000/469 | Gen/Dis Loss: 0.8527/0.6152\n",
            "Epoch: 055/100 | Batch 100/469 | Gen/Dis Loss: 0.9040/0.6099\n",
            "Epoch: 055/100 | Batch 200/469 | Gen/Dis Loss: 1.1825/0.5684\n",
            "Epoch: 055/100 | Batch 300/469 | Gen/Dis Loss: 0.7757/0.6080\n",
            "Epoch: 055/100 | Batch 400/469 | Gen/Dis Loss: 1.0339/0.6438\n",
            "Time elapsed: 5.97 min\n",
            "Epoch: 056/100 | Batch 000/469 | Gen/Dis Loss: 0.8483/0.6258\n",
            "Epoch: 056/100 | Batch 100/469 | Gen/Dis Loss: 0.9183/0.6003\n",
            "Epoch: 056/100 | Batch 200/469 | Gen/Dis Loss: 1.3212/0.6530\n",
            "Epoch: 056/100 | Batch 300/469 | Gen/Dis Loss: 0.7388/0.5914\n",
            "Epoch: 056/100 | Batch 400/469 | Gen/Dis Loss: 0.7976/0.6282\n",
            "Time elapsed: 6.08 min\n",
            "Epoch: 057/100 | Batch 000/469 | Gen/Dis Loss: 1.1426/0.5925\n",
            "Epoch: 057/100 | Batch 100/469 | Gen/Dis Loss: 0.9131/0.6148\n",
            "Epoch: 057/100 | Batch 200/469 | Gen/Dis Loss: 0.8652/0.6067\n",
            "Epoch: 057/100 | Batch 300/469 | Gen/Dis Loss: 0.9934/0.5863\n",
            "Epoch: 057/100 | Batch 400/469 | Gen/Dis Loss: 1.0300/0.6287\n",
            "Time elapsed: 6.19 min\n",
            "Epoch: 058/100 | Batch 000/469 | Gen/Dis Loss: 0.9622/0.6413\n",
            "Epoch: 058/100 | Batch 100/469 | Gen/Dis Loss: 1.1247/0.6167\n",
            "Epoch: 058/100 | Batch 200/469 | Gen/Dis Loss: 0.7368/0.6459\n",
            "Epoch: 058/100 | Batch 300/469 | Gen/Dis Loss: 0.9854/0.5896\n",
            "Epoch: 058/100 | Batch 400/469 | Gen/Dis Loss: 1.0588/0.6095\n",
            "Time elapsed: 6.30 min\n",
            "Epoch: 059/100 | Batch 000/469 | Gen/Dis Loss: 0.9336/0.5821\n",
            "Epoch: 059/100 | Batch 100/469 | Gen/Dis Loss: 1.0843/0.6234\n",
            "Epoch: 059/100 | Batch 200/469 | Gen/Dis Loss: 0.8664/0.6075\n",
            "Epoch: 059/100 | Batch 300/469 | Gen/Dis Loss: 0.9219/0.6368\n",
            "Epoch: 059/100 | Batch 400/469 | Gen/Dis Loss: 0.9788/0.5701\n",
            "Time elapsed: 6.40 min\n",
            "Epoch: 060/100 | Batch 000/469 | Gen/Dis Loss: 0.7896/0.6157\n",
            "Epoch: 060/100 | Batch 100/469 | Gen/Dis Loss: 0.9064/0.6370\n",
            "Epoch: 060/100 | Batch 200/469 | Gen/Dis Loss: 0.9383/0.5994\n",
            "Epoch: 060/100 | Batch 300/469 | Gen/Dis Loss: 0.9790/0.6229\n",
            "Epoch: 060/100 | Batch 400/469 | Gen/Dis Loss: 1.0973/0.5627\n",
            "Time elapsed: 6.51 min\n",
            "Epoch: 061/100 | Batch 000/469 | Gen/Dis Loss: 0.9240/0.6042\n",
            "Epoch: 061/100 | Batch 100/469 | Gen/Dis Loss: 0.9398/0.6472\n",
            "Epoch: 061/100 | Batch 200/469 | Gen/Dis Loss: 0.7751/0.6307\n",
            "Epoch: 061/100 | Batch 300/469 | Gen/Dis Loss: 0.8537/0.5913\n",
            "Epoch: 061/100 | Batch 400/469 | Gen/Dis Loss: 1.0065/0.6707\n",
            "Time elapsed: 6.62 min\n",
            "Epoch: 062/100 | Batch 000/469 | Gen/Dis Loss: 0.8225/0.6555\n",
            "Epoch: 062/100 | Batch 100/469 | Gen/Dis Loss: 0.9773/0.5618\n",
            "Epoch: 062/100 | Batch 200/469 | Gen/Dis Loss: 0.7932/0.6328\n",
            "Epoch: 062/100 | Batch 300/469 | Gen/Dis Loss: 0.8069/0.6237\n",
            "Epoch: 062/100 | Batch 400/469 | Gen/Dis Loss: 1.0239/0.5689\n",
            "Time elapsed: 6.72 min\n",
            "Epoch: 063/100 | Batch 000/469 | Gen/Dis Loss: 0.8029/0.6157\n",
            "Epoch: 063/100 | Batch 100/469 | Gen/Dis Loss: 0.9036/0.5845\n",
            "Epoch: 063/100 | Batch 200/469 | Gen/Dis Loss: 0.9438/0.5821\n",
            "Epoch: 063/100 | Batch 300/469 | Gen/Dis Loss: 0.7700/0.6625\n",
            "Epoch: 063/100 | Batch 400/469 | Gen/Dis Loss: 1.0521/0.6092\n",
            "Time elapsed: 6.83 min\n",
            "Epoch: 064/100 | Batch 000/469 | Gen/Dis Loss: 1.2977/0.6383\n",
            "Epoch: 064/100 | Batch 100/469 | Gen/Dis Loss: 0.8356/0.6507\n",
            "Epoch: 064/100 | Batch 200/469 | Gen/Dis Loss: 0.8751/0.6131\n",
            "Epoch: 064/100 | Batch 300/469 | Gen/Dis Loss: 0.8876/0.6214\n",
            "Epoch: 064/100 | Batch 400/469 | Gen/Dis Loss: 0.8946/0.6013\n",
            "Time elapsed: 6.94 min\n",
            "Epoch: 065/100 | Batch 000/469 | Gen/Dis Loss: 0.8716/0.5976\n",
            "Epoch: 065/100 | Batch 100/469 | Gen/Dis Loss: 0.9021/0.6460\n",
            "Epoch: 065/100 | Batch 200/469 | Gen/Dis Loss: 0.8756/0.6416\n",
            "Epoch: 065/100 | Batch 300/469 | Gen/Dis Loss: 0.8641/0.6324\n",
            "Epoch: 065/100 | Batch 400/469 | Gen/Dis Loss: 1.0168/0.6352\n",
            "Time elapsed: 7.05 min\n",
            "Epoch: 066/100 | Batch 000/469 | Gen/Dis Loss: 0.7996/0.6191\n",
            "Epoch: 066/100 | Batch 100/469 | Gen/Dis Loss: 0.8686/0.6461\n",
            "Epoch: 066/100 | Batch 200/469 | Gen/Dis Loss: 1.0016/0.6152\n",
            "Epoch: 066/100 | Batch 300/469 | Gen/Dis Loss: 1.0617/0.5754\n",
            "Epoch: 066/100 | Batch 400/469 | Gen/Dis Loss: 0.8326/0.6381\n",
            "Time elapsed: 7.16 min\n",
            "Epoch: 067/100 | Batch 000/469 | Gen/Dis Loss: 1.0715/0.6531\n",
            "Epoch: 067/100 | Batch 100/469 | Gen/Dis Loss: 0.8701/0.6754\n",
            "Epoch: 067/100 | Batch 200/469 | Gen/Dis Loss: 0.9977/0.5955\n",
            "Epoch: 067/100 | Batch 300/469 | Gen/Dis Loss: 0.8395/0.6267\n",
            "Epoch: 067/100 | Batch 400/469 | Gen/Dis Loss: 0.8794/0.6274\n",
            "Time elapsed: 7.27 min\n",
            "Epoch: 068/100 | Batch 000/469 | Gen/Dis Loss: 0.8781/0.6538\n",
            "Epoch: 068/100 | Batch 100/469 | Gen/Dis Loss: 1.0028/0.6410\n",
            "Epoch: 068/100 | Batch 200/469 | Gen/Dis Loss: 0.9151/0.6093\n",
            "Epoch: 068/100 | Batch 300/469 | Gen/Dis Loss: 1.0697/0.5815\n",
            "Epoch: 068/100 | Batch 400/469 | Gen/Dis Loss: 0.9519/0.6292\n",
            "Time elapsed: 7.37 min\n",
            "Epoch: 069/100 | Batch 000/469 | Gen/Dis Loss: 0.9179/0.6284\n",
            "Epoch: 069/100 | Batch 100/469 | Gen/Dis Loss: 0.8787/0.6497\n",
            "Epoch: 069/100 | Batch 200/469 | Gen/Dis Loss: 0.9736/0.6100\n",
            "Epoch: 069/100 | Batch 300/469 | Gen/Dis Loss: 0.9755/0.6011\n",
            "Epoch: 069/100 | Batch 400/469 | Gen/Dis Loss: 0.9628/0.6364\n",
            "Time elapsed: 7.48 min\n",
            "Epoch: 070/100 | Batch 000/469 | Gen/Dis Loss: 1.0201/0.6278\n",
            "Epoch: 070/100 | Batch 100/469 | Gen/Dis Loss: 1.0381/0.6084\n",
            "Epoch: 070/100 | Batch 200/469 | Gen/Dis Loss: 1.0596/0.6363\n",
            "Epoch: 070/100 | Batch 300/469 | Gen/Dis Loss: 1.0414/0.6160\n",
            "Epoch: 070/100 | Batch 400/469 | Gen/Dis Loss: 1.4061/0.6139\n",
            "Time elapsed: 7.59 min\n",
            "Epoch: 071/100 | Batch 000/469 | Gen/Dis Loss: 0.9497/0.5979\n",
            "Epoch: 071/100 | Batch 100/469 | Gen/Dis Loss: 0.8630/0.6374\n",
            "Epoch: 071/100 | Batch 200/469 | Gen/Dis Loss: 0.8497/0.6277\n",
            "Epoch: 071/100 | Batch 300/469 | Gen/Dis Loss: 0.7707/0.6254\n",
            "Epoch: 071/100 | Batch 400/469 | Gen/Dis Loss: 1.0426/0.6112\n",
            "Time elapsed: 7.70 min\n",
            "Epoch: 072/100 | Batch 000/469 | Gen/Dis Loss: 1.1019/0.6457\n",
            "Epoch: 072/100 | Batch 100/469 | Gen/Dis Loss: 0.8545/0.6029\n",
            "Epoch: 072/100 | Batch 200/469 | Gen/Dis Loss: 0.8744/0.5965\n",
            "Epoch: 072/100 | Batch 300/469 | Gen/Dis Loss: 0.9046/0.6302\n",
            "Epoch: 072/100 | Batch 400/469 | Gen/Dis Loss: 0.8839/0.6168\n",
            "Time elapsed: 7.81 min\n",
            "Epoch: 073/100 | Batch 000/469 | Gen/Dis Loss: 0.9621/0.6208\n",
            "Epoch: 073/100 | Batch 100/469 | Gen/Dis Loss: 0.8900/0.6464\n",
            "Epoch: 073/100 | Batch 200/469 | Gen/Dis Loss: 0.9544/0.6285\n",
            "Epoch: 073/100 | Batch 300/469 | Gen/Dis Loss: 0.9870/0.6415\n",
            "Epoch: 073/100 | Batch 400/469 | Gen/Dis Loss: 1.1356/0.6022\n",
            "Time elapsed: 7.92 min\n",
            "Epoch: 074/100 | Batch 000/469 | Gen/Dis Loss: 1.0075/0.6134\n",
            "Epoch: 074/100 | Batch 100/469 | Gen/Dis Loss: 1.0741/0.5765\n",
            "Epoch: 074/100 | Batch 200/469 | Gen/Dis Loss: 0.7832/0.6808\n",
            "Epoch: 074/100 | Batch 300/469 | Gen/Dis Loss: 0.8781/0.6190\n",
            "Epoch: 074/100 | Batch 400/469 | Gen/Dis Loss: 0.8576/0.6319\n",
            "Time elapsed: 8.03 min\n",
            "Epoch: 075/100 | Batch 000/469 | Gen/Dis Loss: 0.9374/0.6267\n",
            "Epoch: 075/100 | Batch 100/469 | Gen/Dis Loss: 1.0743/0.6477\n",
            "Epoch: 075/100 | Batch 200/469 | Gen/Dis Loss: 0.9859/0.6121\n",
            "Epoch: 075/100 | Batch 300/469 | Gen/Dis Loss: 1.0527/0.5881\n",
            "Epoch: 075/100 | Batch 400/469 | Gen/Dis Loss: 0.9160/0.6250\n",
            "Time elapsed: 8.14 min\n",
            "Epoch: 076/100 | Batch 000/469 | Gen/Dis Loss: 0.9649/0.6010\n",
            "Epoch: 076/100 | Batch 100/469 | Gen/Dis Loss: 0.9165/0.6357\n",
            "Epoch: 076/100 | Batch 200/469 | Gen/Dis Loss: 0.8363/0.5953\n",
            "Epoch: 076/100 | Batch 300/469 | Gen/Dis Loss: 0.9497/0.6291\n",
            "Epoch: 076/100 | Batch 400/469 | Gen/Dis Loss: 0.9470/0.5737\n",
            "Time elapsed: 8.24 min\n",
            "Epoch: 077/100 | Batch 000/469 | Gen/Dis Loss: 0.9061/0.5837\n",
            "Epoch: 077/100 | Batch 100/469 | Gen/Dis Loss: 0.9212/0.6303\n",
            "Epoch: 077/100 | Batch 200/469 | Gen/Dis Loss: 1.0134/0.6079\n",
            "Epoch: 077/100 | Batch 300/469 | Gen/Dis Loss: 0.8076/0.6302\n",
            "Epoch: 077/100 | Batch 400/469 | Gen/Dis Loss: 0.8510/0.6471\n",
            "Time elapsed: 8.35 min\n",
            "Epoch: 078/100 | Batch 000/469 | Gen/Dis Loss: 0.8824/0.5925\n",
            "Epoch: 078/100 | Batch 100/469 | Gen/Dis Loss: 0.8147/0.6316\n",
            "Epoch: 078/100 | Batch 200/469 | Gen/Dis Loss: 0.9574/0.5718\n",
            "Epoch: 078/100 | Batch 300/469 | Gen/Dis Loss: 1.1151/0.5786\n",
            "Epoch: 078/100 | Batch 400/469 | Gen/Dis Loss: 0.9138/0.6483\n",
            "Time elapsed: 8.46 min\n",
            "Epoch: 079/100 | Batch 000/469 | Gen/Dis Loss: 0.9095/0.6405\n",
            "Epoch: 079/100 | Batch 100/469 | Gen/Dis Loss: 0.8715/0.5953\n",
            "Epoch: 079/100 | Batch 200/469 | Gen/Dis Loss: 0.7997/0.6130\n",
            "Epoch: 079/100 | Batch 300/469 | Gen/Dis Loss: 0.9415/0.5715\n",
            "Epoch: 079/100 | Batch 400/469 | Gen/Dis Loss: 0.8364/0.6060\n",
            "Time elapsed: 8.57 min\n",
            "Epoch: 080/100 | Batch 000/469 | Gen/Dis Loss: 0.8267/0.6302\n",
            "Epoch: 080/100 | Batch 100/469 | Gen/Dis Loss: 0.9921/0.5994\n",
            "Epoch: 080/100 | Batch 200/469 | Gen/Dis Loss: 1.0653/0.5896\n",
            "Epoch: 080/100 | Batch 300/469 | Gen/Dis Loss: 1.0231/0.5671\n",
            "Epoch: 080/100 | Batch 400/469 | Gen/Dis Loss: 0.9531/0.6422\n",
            "Time elapsed: 8.67 min\n",
            "Epoch: 081/100 | Batch 000/469 | Gen/Dis Loss: 0.9247/0.6029\n",
            "Epoch: 081/100 | Batch 100/469 | Gen/Dis Loss: 0.8606/0.6431\n",
            "Epoch: 081/100 | Batch 200/469 | Gen/Dis Loss: 0.7572/0.6478\n",
            "Epoch: 081/100 | Batch 300/469 | Gen/Dis Loss: 0.9635/0.5968\n",
            "Epoch: 081/100 | Batch 400/469 | Gen/Dis Loss: 0.7871/0.6109\n",
            "Time elapsed: 8.78 min\n",
            "Epoch: 082/100 | Batch 000/469 | Gen/Dis Loss: 0.8224/0.6171\n",
            "Epoch: 082/100 | Batch 100/469 | Gen/Dis Loss: 0.9276/0.5943\n",
            "Epoch: 082/100 | Batch 200/469 | Gen/Dis Loss: 1.0118/0.6088\n",
            "Epoch: 082/100 | Batch 300/469 | Gen/Dis Loss: 1.3553/0.5593\n",
            "Epoch: 082/100 | Batch 400/469 | Gen/Dis Loss: 0.9244/0.5965\n",
            "Time elapsed: 8.89 min\n",
            "Epoch: 083/100 | Batch 000/469 | Gen/Dis Loss: 0.8931/0.6139\n",
            "Epoch: 083/100 | Batch 100/469 | Gen/Dis Loss: 0.8311/0.6394\n",
            "Epoch: 083/100 | Batch 200/469 | Gen/Dis Loss: 0.8981/0.5773\n",
            "Epoch: 083/100 | Batch 300/469 | Gen/Dis Loss: 0.9237/0.6030\n",
            "Epoch: 083/100 | Batch 400/469 | Gen/Dis Loss: 0.8242/0.6342\n",
            "Time elapsed: 9.00 min\n",
            "Epoch: 084/100 | Batch 000/469 | Gen/Dis Loss: 1.0407/0.5955\n",
            "Epoch: 084/100 | Batch 100/469 | Gen/Dis Loss: 0.9416/0.6241\n",
            "Epoch: 084/100 | Batch 200/469 | Gen/Dis Loss: 1.0647/0.5871\n",
            "Epoch: 084/100 | Batch 300/469 | Gen/Dis Loss: 0.7439/0.6276\n",
            "Epoch: 084/100 | Batch 400/469 | Gen/Dis Loss: 0.8838/0.6508\n",
            "Time elapsed: 9.10 min\n",
            "Epoch: 085/100 | Batch 000/469 | Gen/Dis Loss: 1.0232/0.5706\n",
            "Epoch: 085/100 | Batch 100/469 | Gen/Dis Loss: 0.9079/0.5812\n",
            "Epoch: 085/100 | Batch 200/469 | Gen/Dis Loss: 1.0065/0.6105\n",
            "Epoch: 085/100 | Batch 300/469 | Gen/Dis Loss: 0.8493/0.6358\n",
            "Epoch: 085/100 | Batch 400/469 | Gen/Dis Loss: 0.8780/0.6224\n",
            "Time elapsed: 9.21 min\n",
            "Epoch: 086/100 | Batch 000/469 | Gen/Dis Loss: 0.8222/0.6482\n",
            "Epoch: 086/100 | Batch 100/469 | Gen/Dis Loss: 1.3354/0.5625\n",
            "Epoch: 086/100 | Batch 200/469 | Gen/Dis Loss: 0.9036/0.6061\n",
            "Epoch: 086/100 | Batch 300/469 | Gen/Dis Loss: 0.9721/0.5948\n",
            "Epoch: 086/100 | Batch 400/469 | Gen/Dis Loss: 0.8663/0.6040\n",
            "Time elapsed: 9.32 min\n",
            "Epoch: 087/100 | Batch 000/469 | Gen/Dis Loss: 0.8094/0.6101\n",
            "Epoch: 087/100 | Batch 100/469 | Gen/Dis Loss: 0.9153/0.5954\n",
            "Epoch: 087/100 | Batch 200/469 | Gen/Dis Loss: 0.7949/0.6606\n",
            "Epoch: 087/100 | Batch 300/469 | Gen/Dis Loss: 0.8978/0.6114\n",
            "Epoch: 087/100 | Batch 400/469 | Gen/Dis Loss: 0.9674/0.5975\n",
            "Time elapsed: 9.42 min\n",
            "Epoch: 088/100 | Batch 000/469 | Gen/Dis Loss: 1.0101/0.5848\n",
            "Epoch: 088/100 | Batch 100/469 | Gen/Dis Loss: 0.9809/0.6349\n",
            "Epoch: 088/100 | Batch 200/469 | Gen/Dis Loss: 0.8649/0.6459\n",
            "Epoch: 088/100 | Batch 300/469 | Gen/Dis Loss: 1.0086/0.6289\n",
            "Epoch: 088/100 | Batch 400/469 | Gen/Dis Loss: 0.9162/0.6696\n",
            "Time elapsed: 9.53 min\n",
            "Epoch: 089/100 | Batch 000/469 | Gen/Dis Loss: 1.0750/0.6131\n",
            "Epoch: 089/100 | Batch 100/469 | Gen/Dis Loss: 1.0167/0.6244\n",
            "Epoch: 089/100 | Batch 200/469 | Gen/Dis Loss: 0.9510/0.6078\n",
            "Epoch: 089/100 | Batch 300/469 | Gen/Dis Loss: 0.8544/0.6464\n",
            "Epoch: 089/100 | Batch 400/469 | Gen/Dis Loss: 1.2636/0.6543\n",
            "Time elapsed: 9.64 min\n",
            "Epoch: 090/100 | Batch 000/469 | Gen/Dis Loss: 0.8056/0.6094\n",
            "Epoch: 090/100 | Batch 100/469 | Gen/Dis Loss: 0.8124/0.6032\n",
            "Epoch: 090/100 | Batch 200/469 | Gen/Dis Loss: 0.9531/0.6130\n",
            "Epoch: 090/100 | Batch 300/469 | Gen/Dis Loss: 0.8619/0.6348\n",
            "Epoch: 090/100 | Batch 400/469 | Gen/Dis Loss: 0.8405/0.6389\n",
            "Time elapsed: 9.75 min\n",
            "Epoch: 091/100 | Batch 000/469 | Gen/Dis Loss: 0.7981/0.6633\n",
            "Epoch: 091/100 | Batch 100/469 | Gen/Dis Loss: 0.8978/0.6184\n",
            "Epoch: 091/100 | Batch 200/469 | Gen/Dis Loss: 0.8640/0.6044\n",
            "Epoch: 091/100 | Batch 300/469 | Gen/Dis Loss: 0.8124/0.6024\n",
            "Epoch: 091/100 | Batch 400/469 | Gen/Dis Loss: 0.9973/0.6183\n",
            "Time elapsed: 9.85 min\n",
            "Epoch: 092/100 | Batch 000/469 | Gen/Dis Loss: 0.8751/0.6421\n",
            "Epoch: 092/100 | Batch 100/469 | Gen/Dis Loss: 0.8409/0.6199\n",
            "Epoch: 092/100 | Batch 200/469 | Gen/Dis Loss: 0.8447/0.6264\n",
            "Epoch: 092/100 | Batch 300/469 | Gen/Dis Loss: 0.8223/0.6471\n",
            "Epoch: 092/100 | Batch 400/469 | Gen/Dis Loss: 0.8218/0.6119\n",
            "Time elapsed: 9.96 min\n",
            "Epoch: 093/100 | Batch 000/469 | Gen/Dis Loss: 1.1010/0.5743\n",
            "Epoch: 093/100 | Batch 100/469 | Gen/Dis Loss: 1.0002/0.6315\n",
            "Epoch: 093/100 | Batch 200/469 | Gen/Dis Loss: 0.9136/0.6066\n",
            "Epoch: 093/100 | Batch 300/469 | Gen/Dis Loss: 0.8759/0.6146\n",
            "Epoch: 093/100 | Batch 400/469 | Gen/Dis Loss: 1.0094/0.6481\n",
            "Time elapsed: 10.07 min\n",
            "Epoch: 094/100 | Batch 000/469 | Gen/Dis Loss: 0.8512/0.6484\n",
            "Epoch: 094/100 | Batch 100/469 | Gen/Dis Loss: 0.8119/0.6076\n",
            "Epoch: 094/100 | Batch 200/469 | Gen/Dis Loss: 1.1606/0.6045\n",
            "Epoch: 094/100 | Batch 300/469 | Gen/Dis Loss: 0.9040/0.6475\n",
            "Epoch: 094/100 | Batch 400/469 | Gen/Dis Loss: 0.9234/0.6189\n",
            "Time elapsed: 10.17 min\n",
            "Epoch: 095/100 | Batch 000/469 | Gen/Dis Loss: 1.3605/0.5952\n",
            "Epoch: 095/100 | Batch 100/469 | Gen/Dis Loss: 0.9350/0.5846\n",
            "Epoch: 095/100 | Batch 200/469 | Gen/Dis Loss: 0.9426/0.6555\n",
            "Epoch: 095/100 | Batch 300/469 | Gen/Dis Loss: 1.0739/0.6282\n",
            "Epoch: 095/100 | Batch 400/469 | Gen/Dis Loss: 0.8661/0.6129\n",
            "Time elapsed: 10.28 min\n",
            "Epoch: 096/100 | Batch 000/469 | Gen/Dis Loss: 1.0401/0.5656\n",
            "Epoch: 096/100 | Batch 100/469 | Gen/Dis Loss: 0.9128/0.6130\n",
            "Epoch: 096/100 | Batch 200/469 | Gen/Dis Loss: 1.0113/0.5901\n",
            "Epoch: 096/100 | Batch 300/469 | Gen/Dis Loss: 0.9222/0.6437\n",
            "Epoch: 096/100 | Batch 400/469 | Gen/Dis Loss: 0.7847/0.6722\n",
            "Time elapsed: 10.39 min\n",
            "Epoch: 097/100 | Batch 000/469 | Gen/Dis Loss: 0.9057/0.5840\n",
            "Epoch: 097/100 | Batch 100/469 | Gen/Dis Loss: 0.8071/0.6251\n",
            "Epoch: 097/100 | Batch 200/469 | Gen/Dis Loss: 0.7611/0.6444\n",
            "Epoch: 097/100 | Batch 300/469 | Gen/Dis Loss: 0.9092/0.6175\n",
            "Epoch: 097/100 | Batch 400/469 | Gen/Dis Loss: 0.8961/0.6268\n",
            "Time elapsed: 10.49 min\n",
            "Epoch: 098/100 | Batch 000/469 | Gen/Dis Loss: 0.8321/0.6343\n",
            "Epoch: 098/100 | Batch 100/469 | Gen/Dis Loss: 0.9693/0.5808\n",
            "Epoch: 098/100 | Batch 200/469 | Gen/Dis Loss: 0.8725/0.6450\n",
            "Epoch: 098/100 | Batch 300/469 | Gen/Dis Loss: 1.0490/0.6251\n",
            "Epoch: 098/100 | Batch 400/469 | Gen/Dis Loss: 1.3341/0.5402\n",
            "Time elapsed: 10.60 min\n",
            "Epoch: 099/100 | Batch 000/469 | Gen/Dis Loss: 1.1148/0.6162\n",
            "Epoch: 099/100 | Batch 100/469 | Gen/Dis Loss: 0.8870/0.6273\n",
            "Epoch: 099/100 | Batch 200/469 | Gen/Dis Loss: 0.8601/0.5906\n",
            "Epoch: 099/100 | Batch 300/469 | Gen/Dis Loss: 0.9210/0.6062\n",
            "Epoch: 099/100 | Batch 400/469 | Gen/Dis Loss: 0.9318/0.6127\n",
            "Time elapsed: 10.71 min\n",
            "Epoch: 100/100 | Batch 000/469 | Gen/Dis Loss: 0.8731/0.6132\n",
            "Epoch: 100/100 | Batch 100/469 | Gen/Dis Loss: 0.9883/0.6006\n",
            "Epoch: 100/100 | Batch 200/469 | Gen/Dis Loss: 0.9052/0.6128\n",
            "Epoch: 100/100 | Batch 300/469 | Gen/Dis Loss: 1.0481/0.5575\n",
            "Epoch: 100/100 | Batch 400/469 | Gen/Dis Loss: 0.9882/0.6397\n",
            "Time elapsed: 10.82 min\n",
            "Total Training Time: 10.82 min\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "qOkXe-richqq",
        "outputId": "e5855d86-12bc-48e3-f425-3ebc11c18dd5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model.eval()\n",
        "# Make new images\n",
        "z = torch.zeros((5, LATENT_DIM)).uniform_(-1.0, 1.0).to(device)\n",
        "generated_features = model.generator_forward(z)\n",
        "imgs = generated_features.view(-1, 28, 28)\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(20, 2.5))\n",
        "\n",
        "\n",
        "for i, ax in enumerate(axes):\n",
        "    axes[i].imshow(imgs[i].to(torch.device('cpu')).detach(), cmap='binary')\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x180 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sK6BUPeDcobd"
      },
      "source": [
        "## CNN GANs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOg0LFKmcv20"
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "    \n",
        "class Reshape1(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), 64, 7, 7)\n",
        "\n",
        "\n",
        "class GAN(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(GAN, self).__init__()\n",
        "        \n",
        "        \n",
        "        self.generator = nn.Sequential(\n",
        "              \n",
        "            nn.Linear(LATENT_DIM, 3136, bias=False),\n",
        "            nn.BatchNorm1d(num_features=3136),\n",
        "            nn.LeakyReLU(inplace=True, negative_slope=0.0001),\n",
        "            Reshape1(),\n",
        "            \n",
        "            nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=(3, 3), stride=(2, 2), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(num_features=32),\n",
        "            nn.LeakyReLU(inplace=True, negative_slope=0.0001),\n",
        "            #nn.Dropout2d(p=0.2),\n",
        "            \n",
        "            nn.ConvTranspose2d(in_channels=32, out_channels=16, kernel_size=(3, 3), stride=(2, 2), padding=1, bias=False),\n",
        "            nn.BatchNorm2d(num_features=16),\n",
        "            nn.LeakyReLU(inplace=True, negative_slope=0.0001),\n",
        "            #nn.Dropout2d(p=0.2),\n",
        "            \n",
        "            nn.ConvTranspose2d(in_channels=16, out_channels=8, kernel_size=(3, 3), stride=(1, 1), padding=0, bias=False),\n",
        "            nn.BatchNorm2d(num_features=8),\n",
        "            nn.LeakyReLU(inplace=True, negative_slope=0.0001),\n",
        "            #nn.Dropout2d(p=0.2),\n",
        "            \n",
        "            nn.ConvTranspose2d(in_channels=8, out_channels=1, kernel_size=(2, 2), stride=(1, 1), padding=0, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "        \n",
        "        self.discriminator = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=8, padding=1, kernel_size=(3, 3), stride=(2, 2), bias=False),\n",
        "            nn.BatchNorm2d(num_features=8),\n",
        "            nn.LeakyReLU(inplace=True, negative_slope=0.0001), \n",
        "            #nn.Dropout2d(p=0.2),\n",
        "            \n",
        "            nn.Conv2d(in_channels=8, out_channels=32, padding=1, kernel_size=(3, 3), stride=(2, 2), bias=False),\n",
        "            nn.BatchNorm2d(num_features=32),\n",
        "            nn.LeakyReLU(inplace=True, negative_slope=0.0001), \n",
        "            #nn.Dropout2d(p=0.2),\n",
        "            \n",
        "            Flatten(),\n",
        "\n",
        "            nn.Linear(7*7*32, 1),\n",
        "            #nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "            \n",
        "    def generator_forward(self, z):\n",
        "        img = self.generator(z)\n",
        "        return img\n",
        "    \n",
        "    def discriminator_forward(self, img):\n",
        "        pred = model.discriminator(img)\n",
        "        return pred.view(-1)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEdzDiNtdnPF",
        "outputId": "53a62cf4-231d-41dc-d1a7-baf79120fb39"
      },
      "source": [
        "torch.manual_seed(random_seed)\n",
        "\n",
        "\n",
        "model = GAN()\n",
        "model = model.to(device)\n",
        "\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GAN(\n",
            "  (generator): Sequential(\n",
            "    (0): Linear(in_features=100, out_features=3136, bias=False)\n",
            "    (1): BatchNorm1d(3136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.0001, inplace=True)\n",
            "    (3): Reshape1()\n",
            "    (4): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): LeakyReLU(negative_slope=0.0001, inplace=True)\n",
            "    (7): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (8): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): LeakyReLU(negative_slope=0.0001, inplace=True)\n",
            "    (10): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (11): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): LeakyReLU(negative_slope=0.0001, inplace=True)\n",
            "    (13): ConvTranspose2d(8, 1, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
            "    (14): Tanh()\n",
            "  )\n",
            "  (discriminator): Sequential(\n",
            "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.0001, inplace=True)\n",
            "    (3): Conv2d(8, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): LeakyReLU(negative_slope=0.0001, inplace=True)\n",
            "    (6): Flatten()\n",
            "    (7): Linear(in_features=1568, out_features=1, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-zhbBDfdrvn"
      },
      "source": [
        "optim_gener = torch.optim.Adam(model.generator.parameters(), lr=generator_learning_rate)\n",
        "optim_discr = torch.optim.Adam(model.discriminator.parameters(), lr=discriminator_learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YT-rjlu4dvwW",
        "outputId": "b2cdbf3d-8631-4f63-d9d1-f9d9671e9452"
      },
      "source": [
        "start_time = time.time()    \n",
        "\n",
        "discr_costs = []\n",
        "gener_costs = []\n",
        "for epoch in range(num_epochs):\n",
        "    model = model.train()\n",
        "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
        "\n",
        "        \n",
        "        # Normalize images to [-1, 1] range\n",
        "        features = (features - 0.5)*2.\n",
        "        features = features.view(-1, IMG_SIZE).to(device) \n",
        "\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        valid = torch.ones(targets.size(0)).float().to(device)\n",
        "        fake = torch.zeros(targets.size(0)).float().to(device)\n",
        "        \n",
        "\n",
        "        ### FORWARD AND BACK PROP\n",
        "        \n",
        "        \n",
        "        # --------------------------\n",
        "        # Train Generator\n",
        "        # --------------------------\n",
        "        \n",
        "        # Make new images\n",
        "        z = torch.zeros((targets.size(0), LATENT_DIM)).uniform_(-1.0, 1.0).to(device)\n",
        "        generated_features = model.generator_forward(z)\n",
        "        \n",
        "        # Loss for fooling the discriminator\n",
        "        discr_pred = model.discriminator_forward(generated_features.view(targets.size(0), 1, 28, 28))\n",
        "        \n",
        "        gener_loss = F.binary_cross_entropy_with_logits(discr_pred, valid)\n",
        "        \n",
        "        optim_gener.zero_grad()\n",
        "        gener_loss.backward()\n",
        "        optim_gener.step()\n",
        "        \n",
        "        # --------------------------\n",
        "        # Train Discriminator\n",
        "        # --------------------------        \n",
        "        \n",
        "        discr_pred_real = model.discriminator_forward(features.view(targets.size(0), 1, 28, 28))\n",
        "        real_loss = F.binary_cross_entropy_with_logits(discr_pred_real, valid)\n",
        "        \n",
        "        discr_pred_fake = model.discriminator_forward(generated_features.view(targets.size(0), 1, 28, 28).detach())\n",
        "        fake_loss = F.binary_cross_entropy_with_logits(discr_pred_fake, fake)\n",
        "        \n",
        "        discr_loss = 0.5*(real_loss + fake_loss)\n",
        "\n",
        "        optim_discr.zero_grad()\n",
        "        discr_loss.backward()\n",
        "        optim_discr.step()        \n",
        "        \n",
        "        discr_costs.append(discr_loss.item())\n",
        "        gener_costs.append(gener_loss.item())\n",
        "        \n",
        "        \n",
        "        ### LOGGING\n",
        "        if not batch_idx % 100:\n",
        "            print ('Epoch: %03d/%03d | Batch %03d/%03d | Gen/Dis Loss: %.4f/%.4f' \n",
        "                   %(epoch+1, num_epochs, batch_idx, \n",
        "                     len(train_loader), gener_loss, discr_loss))\n",
        "\n",
        "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
        "    \n",
        "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 001/100 | Batch 000/469 | Gen/Dis Loss: 0.8375/0.7570\n",
            "Epoch: 001/100 | Batch 100/469 | Gen/Dis Loss: 3.4745/0.0420\n",
            "Epoch: 001/100 | Batch 200/469 | Gen/Dis Loss: 3.2341/0.0340\n",
            "Epoch: 001/100 | Batch 300/469 | Gen/Dis Loss: 5.5831/0.0140\n",
            "Epoch: 001/100 | Batch 400/469 | Gen/Dis Loss: 3.5889/0.0522\n",
            "Time elapsed: 0.14 min\n",
            "Epoch: 002/100 | Batch 000/469 | Gen/Dis Loss: 3.6528/0.0590\n",
            "Epoch: 002/100 | Batch 100/469 | Gen/Dis Loss: 3.7954/0.0495\n",
            "Epoch: 002/100 | Batch 200/469 | Gen/Dis Loss: 3.0547/0.0988\n",
            "Epoch: 002/100 | Batch 300/469 | Gen/Dis Loss: 7.8777/0.0063\n",
            "Epoch: 002/100 | Batch 400/469 | Gen/Dis Loss: 2.9377/0.0925\n",
            "Time elapsed: 0.28 min\n",
            "Epoch: 003/100 | Batch 000/469 | Gen/Dis Loss: 4.6084/0.0368\n",
            "Epoch: 003/100 | Batch 100/469 | Gen/Dis Loss: 2.2283/0.2597\n",
            "Epoch: 003/100 | Batch 200/469 | Gen/Dis Loss: 4.1558/0.0408\n",
            "Epoch: 003/100 | Batch 300/469 | Gen/Dis Loss: 2.6713/0.1626\n",
            "Epoch: 003/100 | Batch 400/469 | Gen/Dis Loss: 3.8227/0.1226\n",
            "Time elapsed: 0.42 min\n",
            "Epoch: 004/100 | Batch 000/469 | Gen/Dis Loss: 2.5137/0.2047\n",
            "Epoch: 004/100 | Batch 100/469 | Gen/Dis Loss: 2.6871/0.1169\n",
            "Epoch: 004/100 | Batch 200/469 | Gen/Dis Loss: 2.0769/0.1995\n",
            "Epoch: 004/100 | Batch 300/469 | Gen/Dis Loss: 2.0538/0.2413\n",
            "Epoch: 004/100 | Batch 400/469 | Gen/Dis Loss: 2.2226/0.1500\n",
            "Time elapsed: 0.56 min\n",
            "Epoch: 005/100 | Batch 000/469 | Gen/Dis Loss: 1.7153/0.2682\n",
            "Epoch: 005/100 | Batch 100/469 | Gen/Dis Loss: 2.6565/0.1461\n",
            "Epoch: 005/100 | Batch 200/469 | Gen/Dis Loss: 2.2824/0.1831\n",
            "Epoch: 005/100 | Batch 300/469 | Gen/Dis Loss: 2.9526/0.1512\n",
            "Epoch: 005/100 | Batch 400/469 | Gen/Dis Loss: 2.0833/0.2370\n",
            "Time elapsed: 0.70 min\n",
            "Epoch: 006/100 | Batch 000/469 | Gen/Dis Loss: 3.8244/0.1350\n",
            "Epoch: 006/100 | Batch 100/469 | Gen/Dis Loss: 2.6045/0.1321\n",
            "Epoch: 006/100 | Batch 200/469 | Gen/Dis Loss: 1.9490/0.2133\n",
            "Epoch: 006/100 | Batch 300/469 | Gen/Dis Loss: 2.1623/0.3272\n",
            "Epoch: 006/100 | Batch 400/469 | Gen/Dis Loss: 2.4758/0.2004\n",
            "Time elapsed: 0.84 min\n",
            "Epoch: 007/100 | Batch 000/469 | Gen/Dis Loss: 1.6085/0.3708\n",
            "Epoch: 007/100 | Batch 100/469 | Gen/Dis Loss: 2.3936/0.1929\n",
            "Epoch: 007/100 | Batch 200/469 | Gen/Dis Loss: 1.4100/0.5625\n",
            "Epoch: 007/100 | Batch 300/469 | Gen/Dis Loss: 1.5428/0.4388\n",
            "Epoch: 007/100 | Batch 400/469 | Gen/Dis Loss: 1.8151/0.3402\n",
            "Time elapsed: 0.98 min\n",
            "Epoch: 008/100 | Batch 000/469 | Gen/Dis Loss: 1.9187/0.3026\n",
            "Epoch: 008/100 | Batch 100/469 | Gen/Dis Loss: 2.4062/0.3760\n",
            "Epoch: 008/100 | Batch 200/469 | Gen/Dis Loss: 1.5748/0.3882\n",
            "Epoch: 008/100 | Batch 300/469 | Gen/Dis Loss: 1.7231/0.3877\n",
            "Epoch: 008/100 | Batch 400/469 | Gen/Dis Loss: 2.0907/0.3250\n",
            "Time elapsed: 1.12 min\n",
            "Epoch: 009/100 | Batch 000/469 | Gen/Dis Loss: 2.5205/0.2952\n",
            "Epoch: 009/100 | Batch 100/469 | Gen/Dis Loss: 1.7927/0.4145\n",
            "Epoch: 009/100 | Batch 200/469 | Gen/Dis Loss: 2.1275/0.3811\n",
            "Epoch: 009/100 | Batch 300/469 | Gen/Dis Loss: 2.1197/0.3579\n",
            "Epoch: 009/100 | Batch 400/469 | Gen/Dis Loss: 2.3595/0.3634\n",
            "Time elapsed: 1.26 min\n",
            "Epoch: 010/100 | Batch 000/469 | Gen/Dis Loss: 2.5837/0.2477\n",
            "Epoch: 010/100 | Batch 100/469 | Gen/Dis Loss: 2.0611/0.3871\n",
            "Epoch: 010/100 | Batch 200/469 | Gen/Dis Loss: 1.7756/0.4206\n",
            "Epoch: 010/100 | Batch 300/469 | Gen/Dis Loss: 2.1322/0.3960\n",
            "Epoch: 010/100 | Batch 400/469 | Gen/Dis Loss: 1.1172/0.6869\n",
            "Time elapsed: 1.40 min\n",
            "Epoch: 011/100 | Batch 000/469 | Gen/Dis Loss: 1.5517/0.4280\n",
            "Epoch: 011/100 | Batch 100/469 | Gen/Dis Loss: 1.6350/0.3106\n",
            "Epoch: 011/100 | Batch 200/469 | Gen/Dis Loss: 1.6362/0.4507\n",
            "Epoch: 011/100 | Batch 300/469 | Gen/Dis Loss: 1.9294/0.4756\n",
            "Epoch: 011/100 | Batch 400/469 | Gen/Dis Loss: 1.5236/0.4020\n",
            "Time elapsed: 1.54 min\n",
            "Epoch: 012/100 | Batch 000/469 | Gen/Dis Loss: 1.5249/0.6016\n",
            "Epoch: 012/100 | Batch 100/469 | Gen/Dis Loss: 1.4217/0.4837\n",
            "Epoch: 012/100 | Batch 200/469 | Gen/Dis Loss: 1.3318/0.6937\n",
            "Epoch: 012/100 | Batch 300/469 | Gen/Dis Loss: 1.7272/0.4704\n",
            "Epoch: 012/100 | Batch 400/469 | Gen/Dis Loss: 1.7147/0.3125\n",
            "Time elapsed: 1.68 min\n",
            "Epoch: 013/100 | Batch 000/469 | Gen/Dis Loss: 2.0828/0.3093\n",
            "Epoch: 013/100 | Batch 100/469 | Gen/Dis Loss: 1.8794/0.5271\n",
            "Epoch: 013/100 | Batch 200/469 | Gen/Dis Loss: 1.1484/0.6300\n",
            "Epoch: 013/100 | Batch 300/469 | Gen/Dis Loss: 1.3602/0.6077\n",
            "Epoch: 013/100 | Batch 400/469 | Gen/Dis Loss: 1.2865/0.7506\n",
            "Time elapsed: 1.83 min\n",
            "Epoch: 014/100 | Batch 000/469 | Gen/Dis Loss: 1.3418/0.5713\n",
            "Epoch: 014/100 | Batch 100/469 | Gen/Dis Loss: 1.3304/0.7943\n",
            "Epoch: 014/100 | Batch 200/469 | Gen/Dis Loss: 1.6448/0.3818\n",
            "Epoch: 014/100 | Batch 300/469 | Gen/Dis Loss: 1.4530/0.5656\n",
            "Epoch: 014/100 | Batch 400/469 | Gen/Dis Loss: 1.6615/0.4767\n",
            "Time elapsed: 1.96 min\n",
            "Epoch: 015/100 | Batch 000/469 | Gen/Dis Loss: 1.4773/0.4104\n",
            "Epoch: 015/100 | Batch 100/469 | Gen/Dis Loss: 1.1671/0.5656\n",
            "Epoch: 015/100 | Batch 200/469 | Gen/Dis Loss: 1.1178/0.5071\n",
            "Epoch: 015/100 | Batch 300/469 | Gen/Dis Loss: 1.2863/0.4589\n",
            "Epoch: 015/100 | Batch 400/469 | Gen/Dis Loss: 1.4308/0.3864\n",
            "Time elapsed: 2.11 min\n",
            "Epoch: 016/100 | Batch 000/469 | Gen/Dis Loss: 1.3776/0.4240\n",
            "Epoch: 016/100 | Batch 100/469 | Gen/Dis Loss: 1.5412/0.5925\n",
            "Epoch: 016/100 | Batch 200/469 | Gen/Dis Loss: 1.8026/0.4080\n",
            "Epoch: 016/100 | Batch 300/469 | Gen/Dis Loss: 1.5371/0.4879\n",
            "Epoch: 016/100 | Batch 400/469 | Gen/Dis Loss: 1.3709/0.5755\n",
            "Time elapsed: 2.25 min\n",
            "Epoch: 017/100 | Batch 000/469 | Gen/Dis Loss: 1.3221/0.4986\n",
            "Epoch: 017/100 | Batch 100/469 | Gen/Dis Loss: 1.3677/0.5895\n",
            "Epoch: 017/100 | Batch 200/469 | Gen/Dis Loss: 1.4874/0.4970\n",
            "Epoch: 017/100 | Batch 300/469 | Gen/Dis Loss: 1.3912/0.4492\n",
            "Epoch: 017/100 | Batch 400/469 | Gen/Dis Loss: 1.2959/0.6117\n",
            "Time elapsed: 2.39 min\n",
            "Epoch: 018/100 | Batch 000/469 | Gen/Dis Loss: 1.2077/0.4809\n",
            "Epoch: 018/100 | Batch 100/469 | Gen/Dis Loss: 1.5230/0.6176\n",
            "Epoch: 018/100 | Batch 200/469 | Gen/Dis Loss: 1.2215/0.4962\n",
            "Epoch: 018/100 | Batch 300/469 | Gen/Dis Loss: 1.4790/0.6270\n",
            "Epoch: 018/100 | Batch 400/469 | Gen/Dis Loss: 1.0840/0.6880\n",
            "Time elapsed: 2.52 min\n",
            "Epoch: 019/100 | Batch 000/469 | Gen/Dis Loss: 1.2255/0.5393\n",
            "Epoch: 019/100 | Batch 100/469 | Gen/Dis Loss: 2.0063/0.3655\n",
            "Epoch: 019/100 | Batch 200/469 | Gen/Dis Loss: 0.6636/1.0299\n",
            "Epoch: 019/100 | Batch 300/469 | Gen/Dis Loss: 1.3350/0.6724\n",
            "Epoch: 019/100 | Batch 400/469 | Gen/Dis Loss: 1.2430/0.8126\n",
            "Time elapsed: 2.66 min\n",
            "Epoch: 020/100 | Batch 000/469 | Gen/Dis Loss: 1.3186/0.5726\n",
            "Epoch: 020/100 | Batch 100/469 | Gen/Dis Loss: 1.0402/0.5854\n",
            "Epoch: 020/100 | Batch 200/469 | Gen/Dis Loss: 1.1066/0.6457\n",
            "Epoch: 020/100 | Batch 300/469 | Gen/Dis Loss: 1.5866/0.4751\n",
            "Epoch: 020/100 | Batch 400/469 | Gen/Dis Loss: 0.8132/0.6546\n",
            "Time elapsed: 2.80 min\n",
            "Epoch: 021/100 | Batch 000/469 | Gen/Dis Loss: 1.8245/0.6801\n",
            "Epoch: 021/100 | Batch 100/469 | Gen/Dis Loss: 0.9156/0.7109\n",
            "Epoch: 021/100 | Batch 200/469 | Gen/Dis Loss: 1.1437/0.5764\n",
            "Epoch: 021/100 | Batch 300/469 | Gen/Dis Loss: 0.9874/0.6717\n",
            "Epoch: 021/100 | Batch 400/469 | Gen/Dis Loss: 1.1375/0.6472\n",
            "Time elapsed: 2.94 min\n",
            "Epoch: 022/100 | Batch 000/469 | Gen/Dis Loss: 1.3602/0.5257\n",
            "Epoch: 022/100 | Batch 100/469 | Gen/Dis Loss: 1.1039/0.5506\n",
            "Epoch: 022/100 | Batch 200/469 | Gen/Dis Loss: 0.8669/0.7243\n",
            "Epoch: 022/100 | Batch 300/469 | Gen/Dis Loss: 1.3978/0.6060\n",
            "Epoch: 022/100 | Batch 400/469 | Gen/Dis Loss: 1.3117/0.5388\n",
            "Time elapsed: 3.08 min\n",
            "Epoch: 023/100 | Batch 000/469 | Gen/Dis Loss: 1.1563/0.5817\n",
            "Epoch: 023/100 | Batch 100/469 | Gen/Dis Loss: 0.9981/0.5871\n",
            "Epoch: 023/100 | Batch 200/469 | Gen/Dis Loss: 0.8759/0.6778\n",
            "Epoch: 023/100 | Batch 300/469 | Gen/Dis Loss: 1.2131/0.5730\n",
            "Epoch: 023/100 | Batch 400/469 | Gen/Dis Loss: 1.2623/0.5299\n",
            "Time elapsed: 3.22 min\n",
            "Epoch: 024/100 | Batch 000/469 | Gen/Dis Loss: 1.0347/0.6681\n",
            "Epoch: 024/100 | Batch 100/469 | Gen/Dis Loss: 1.3497/0.7061\n",
            "Epoch: 024/100 | Batch 200/469 | Gen/Dis Loss: 1.6943/0.4590\n",
            "Epoch: 024/100 | Batch 300/469 | Gen/Dis Loss: 1.1223/0.6888\n",
            "Epoch: 024/100 | Batch 400/469 | Gen/Dis Loss: 1.1221/0.6960\n",
            "Time elapsed: 3.36 min\n",
            "Epoch: 025/100 | Batch 000/469 | Gen/Dis Loss: 1.3443/0.5726\n",
            "Epoch: 025/100 | Batch 100/469 | Gen/Dis Loss: 0.9697/0.5584\n",
            "Epoch: 025/100 | Batch 200/469 | Gen/Dis Loss: 1.0532/0.5535\n",
            "Epoch: 025/100 | Batch 300/469 | Gen/Dis Loss: 1.1321/0.6375\n",
            "Epoch: 025/100 | Batch 400/469 | Gen/Dis Loss: 0.8746/0.6503\n",
            "Time elapsed: 3.50 min\n",
            "Epoch: 026/100 | Batch 000/469 | Gen/Dis Loss: 1.1022/0.7346\n",
            "Epoch: 026/100 | Batch 100/469 | Gen/Dis Loss: 0.9011/0.5576\n",
            "Epoch: 026/100 | Batch 200/469 | Gen/Dis Loss: 0.7494/0.8054\n",
            "Epoch: 026/100 | Batch 300/469 | Gen/Dis Loss: 1.1110/0.5365\n",
            "Epoch: 026/100 | Batch 400/469 | Gen/Dis Loss: 1.6135/0.5544\n",
            "Time elapsed: 3.64 min\n",
            "Epoch: 027/100 | Batch 000/469 | Gen/Dis Loss: 0.8320/0.7127\n",
            "Epoch: 027/100 | Batch 100/469 | Gen/Dis Loss: 1.3252/0.6289\n",
            "Epoch: 027/100 | Batch 200/469 | Gen/Dis Loss: 1.1684/0.5581\n",
            "Epoch: 027/100 | Batch 300/469 | Gen/Dis Loss: 0.9355/0.6695\n",
            "Epoch: 027/100 | Batch 400/469 | Gen/Dis Loss: 1.0589/0.5681\n",
            "Time elapsed: 3.78 min\n",
            "Epoch: 028/100 | Batch 000/469 | Gen/Dis Loss: 1.1087/0.6203\n",
            "Epoch: 028/100 | Batch 100/469 | Gen/Dis Loss: 0.8363/0.6372\n",
            "Epoch: 028/100 | Batch 200/469 | Gen/Dis Loss: 0.8791/0.7274\n",
            "Epoch: 028/100 | Batch 300/469 | Gen/Dis Loss: 1.0839/0.6277\n",
            "Epoch: 028/100 | Batch 400/469 | Gen/Dis Loss: 0.9651/0.5991\n",
            "Time elapsed: 3.92 min\n",
            "Epoch: 029/100 | Batch 000/469 | Gen/Dis Loss: 0.9646/0.6942\n",
            "Epoch: 029/100 | Batch 100/469 | Gen/Dis Loss: 0.9736/0.5867\n",
            "Epoch: 029/100 | Batch 200/469 | Gen/Dis Loss: 1.2951/0.5940\n",
            "Epoch: 029/100 | Batch 300/469 | Gen/Dis Loss: 1.0728/0.5773\n",
            "Epoch: 029/100 | Batch 400/469 | Gen/Dis Loss: 1.2841/0.5726\n",
            "Time elapsed: 4.06 min\n",
            "Epoch: 030/100 | Batch 000/469 | Gen/Dis Loss: 1.1042/0.4711\n",
            "Epoch: 030/100 | Batch 100/469 | Gen/Dis Loss: 0.9325/0.6745\n",
            "Epoch: 030/100 | Batch 200/469 | Gen/Dis Loss: 1.3989/0.5390\n",
            "Epoch: 030/100 | Batch 300/469 | Gen/Dis Loss: 1.1061/0.5245\n",
            "Epoch: 030/100 | Batch 400/469 | Gen/Dis Loss: 0.6044/0.8410\n",
            "Time elapsed: 4.20 min\n",
            "Epoch: 031/100 | Batch 000/469 | Gen/Dis Loss: 1.0756/0.5645\n",
            "Epoch: 031/100 | Batch 100/469 | Gen/Dis Loss: 0.8862/0.6541\n",
            "Epoch: 031/100 | Batch 200/469 | Gen/Dis Loss: 1.0944/0.6551\n",
            "Epoch: 031/100 | Batch 300/469 | Gen/Dis Loss: 0.8284/0.6131\n",
            "Epoch: 031/100 | Batch 400/469 | Gen/Dis Loss: 1.0329/0.6153\n",
            "Time elapsed: 4.34 min\n",
            "Epoch: 032/100 | Batch 000/469 | Gen/Dis Loss: 0.9285/0.7706\n",
            "Epoch: 032/100 | Batch 100/469 | Gen/Dis Loss: 0.9409/0.6583\n",
            "Epoch: 032/100 | Batch 200/469 | Gen/Dis Loss: 0.9379/0.7336\n",
            "Epoch: 032/100 | Batch 300/469 | Gen/Dis Loss: 0.6938/0.7591\n",
            "Epoch: 032/100 | Batch 400/469 | Gen/Dis Loss: 1.0862/0.5388\n",
            "Time elapsed: 4.48 min\n",
            "Epoch: 033/100 | Batch 000/469 | Gen/Dis Loss: 1.0446/0.5675\n",
            "Epoch: 033/100 | Batch 100/469 | Gen/Dis Loss: 1.0022/0.6134\n",
            "Epoch: 033/100 | Batch 200/469 | Gen/Dis Loss: 1.2747/0.5609\n",
            "Epoch: 033/100 | Batch 300/469 | Gen/Dis Loss: 0.8884/0.7998\n",
            "Epoch: 033/100 | Batch 400/469 | Gen/Dis Loss: 0.9280/0.6856\n",
            "Time elapsed: 4.62 min\n",
            "Epoch: 034/100 | Batch 000/469 | Gen/Dis Loss: 0.9445/0.6478\n",
            "Epoch: 034/100 | Batch 100/469 | Gen/Dis Loss: 0.8764/0.7883\n",
            "Epoch: 034/100 | Batch 200/469 | Gen/Dis Loss: 1.2098/0.5725\n",
            "Epoch: 034/100 | Batch 300/469 | Gen/Dis Loss: 1.0238/0.5259\n",
            "Epoch: 034/100 | Batch 400/469 | Gen/Dis Loss: 0.8862/0.6928\n",
            "Time elapsed: 4.75 min\n",
            "Epoch: 035/100 | Batch 000/469 | Gen/Dis Loss: 0.8099/0.7832\n",
            "Epoch: 035/100 | Batch 100/469 | Gen/Dis Loss: 0.6399/0.7335\n",
            "Epoch: 035/100 | Batch 200/469 | Gen/Dis Loss: 0.8285/0.6755\n",
            "Epoch: 035/100 | Batch 300/469 | Gen/Dis Loss: 0.9175/0.6834\n",
            "Epoch: 035/100 | Batch 400/469 | Gen/Dis Loss: 0.8617/0.7686\n",
            "Time elapsed: 4.89 min\n",
            "Epoch: 036/100 | Batch 000/469 | Gen/Dis Loss: 0.7002/0.7377\n",
            "Epoch: 036/100 | Batch 100/469 | Gen/Dis Loss: 0.8819/0.6959\n",
            "Epoch: 036/100 | Batch 200/469 | Gen/Dis Loss: 0.9684/0.6929\n",
            "Epoch: 036/100 | Batch 300/469 | Gen/Dis Loss: 0.9102/0.6220\n",
            "Epoch: 036/100 | Batch 400/469 | Gen/Dis Loss: 0.9690/0.6461\n",
            "Time elapsed: 5.03 min\n",
            "Epoch: 037/100 | Batch 000/469 | Gen/Dis Loss: 0.9576/0.5945\n",
            "Epoch: 037/100 | Batch 100/469 | Gen/Dis Loss: 0.8127/0.7805\n",
            "Epoch: 037/100 | Batch 200/469 | Gen/Dis Loss: 0.9519/0.5332\n",
            "Epoch: 037/100 | Batch 300/469 | Gen/Dis Loss: 0.9604/0.6890\n",
            "Epoch: 037/100 | Batch 400/469 | Gen/Dis Loss: 0.8035/0.7042\n",
            "Time elapsed: 5.17 min\n",
            "Epoch: 038/100 | Batch 000/469 | Gen/Dis Loss: 0.8882/0.7161\n",
            "Epoch: 038/100 | Batch 100/469 | Gen/Dis Loss: 1.2056/0.5118\n",
            "Epoch: 038/100 | Batch 200/469 | Gen/Dis Loss: 0.7246/0.7317\n",
            "Epoch: 038/100 | Batch 300/469 | Gen/Dis Loss: 0.8856/0.6226\n",
            "Epoch: 038/100 | Batch 400/469 | Gen/Dis Loss: 0.9115/0.7053\n",
            "Time elapsed: 5.31 min\n",
            "Epoch: 039/100 | Batch 000/469 | Gen/Dis Loss: 0.8897/0.6991\n",
            "Epoch: 039/100 | Batch 100/469 | Gen/Dis Loss: 0.6622/0.7460\n",
            "Epoch: 039/100 | Batch 200/469 | Gen/Dis Loss: 0.8669/0.6998\n",
            "Epoch: 039/100 | Batch 300/469 | Gen/Dis Loss: 1.0526/0.6247\n",
            "Epoch: 039/100 | Batch 400/469 | Gen/Dis Loss: 0.9360/0.5490\n",
            "Time elapsed: 5.45 min\n",
            "Epoch: 040/100 | Batch 000/469 | Gen/Dis Loss: 0.8822/0.6917\n",
            "Epoch: 040/100 | Batch 100/469 | Gen/Dis Loss: 0.8702/0.7118\n",
            "Epoch: 040/100 | Batch 200/469 | Gen/Dis Loss: 0.7203/0.8022\n",
            "Epoch: 040/100 | Batch 300/469 | Gen/Dis Loss: 0.8242/0.5641\n",
            "Epoch: 040/100 | Batch 400/469 | Gen/Dis Loss: 0.8351/0.6700\n",
            "Time elapsed: 5.58 min\n",
            "Epoch: 041/100 | Batch 000/469 | Gen/Dis Loss: 0.6681/0.8047\n",
            "Epoch: 041/100 | Batch 100/469 | Gen/Dis Loss: 0.9993/0.6060\n",
            "Epoch: 041/100 | Batch 200/469 | Gen/Dis Loss: 0.7719/0.7440\n",
            "Epoch: 041/100 | Batch 300/469 | Gen/Dis Loss: 0.8048/0.6860\n",
            "Epoch: 041/100 | Batch 400/469 | Gen/Dis Loss: 0.7192/0.6964\n",
            "Time elapsed: 5.72 min\n",
            "Epoch: 042/100 | Batch 000/469 | Gen/Dis Loss: 0.9255/0.6423\n",
            "Epoch: 042/100 | Batch 100/469 | Gen/Dis Loss: 1.0432/0.5594\n",
            "Epoch: 042/100 | Batch 200/469 | Gen/Dis Loss: 0.7963/0.7294\n",
            "Epoch: 042/100 | Batch 300/469 | Gen/Dis Loss: 1.0218/0.5894\n",
            "Epoch: 042/100 | Batch 400/469 | Gen/Dis Loss: 0.7125/0.7111\n",
            "Time elapsed: 5.86 min\n",
            "Epoch: 043/100 | Batch 000/469 | Gen/Dis Loss: 0.7656/0.6848\n",
            "Epoch: 043/100 | Batch 100/469 | Gen/Dis Loss: 0.8571/0.6084\n",
            "Epoch: 043/100 | Batch 200/469 | Gen/Dis Loss: 0.7875/0.8112\n",
            "Epoch: 043/100 | Batch 300/469 | Gen/Dis Loss: 0.8795/0.6233\n",
            "Epoch: 043/100 | Batch 400/469 | Gen/Dis Loss: 0.9265/0.6950\n",
            "Time elapsed: 6.00 min\n",
            "Epoch: 044/100 | Batch 000/469 | Gen/Dis Loss: 0.8166/0.6997\n",
            "Epoch: 044/100 | Batch 100/469 | Gen/Dis Loss: 0.8034/0.7400\n",
            "Epoch: 044/100 | Batch 200/469 | Gen/Dis Loss: 0.8942/0.6441\n",
            "Epoch: 044/100 | Batch 300/469 | Gen/Dis Loss: 1.0623/0.5981\n",
            "Epoch: 044/100 | Batch 400/469 | Gen/Dis Loss: 0.7455/0.8414\n",
            "Time elapsed: 6.14 min\n",
            "Epoch: 045/100 | Batch 000/469 | Gen/Dis Loss: 0.9203/0.5597\n",
            "Epoch: 045/100 | Batch 100/469 | Gen/Dis Loss: 0.8489/0.6576\n",
            "Epoch: 045/100 | Batch 200/469 | Gen/Dis Loss: 0.7179/0.7081\n",
            "Epoch: 045/100 | Batch 300/469 | Gen/Dis Loss: 0.8673/0.6513\n",
            "Epoch: 045/100 | Batch 400/469 | Gen/Dis Loss: 0.7673/0.7133\n",
            "Time elapsed: 6.28 min\n",
            "Epoch: 046/100 | Batch 000/469 | Gen/Dis Loss: 0.9036/0.6043\n",
            "Epoch: 046/100 | Batch 100/469 | Gen/Dis Loss: 1.1244/0.5693\n",
            "Epoch: 046/100 | Batch 200/469 | Gen/Dis Loss: 0.8895/0.7934\n",
            "Epoch: 046/100 | Batch 300/469 | Gen/Dis Loss: 0.8375/0.6749\n",
            "Epoch: 046/100 | Batch 400/469 | Gen/Dis Loss: 0.8700/0.7437\n",
            "Time elapsed: 6.41 min\n",
            "Epoch: 047/100 | Batch 000/469 | Gen/Dis Loss: 0.9008/0.7305\n",
            "Epoch: 047/100 | Batch 100/469 | Gen/Dis Loss: 0.9463/0.6126\n",
            "Epoch: 047/100 | Batch 200/469 | Gen/Dis Loss: 0.8605/0.6528\n",
            "Epoch: 047/100 | Batch 300/469 | Gen/Dis Loss: 0.7174/0.6981\n",
            "Epoch: 047/100 | Batch 400/469 | Gen/Dis Loss: 0.9810/0.6770\n",
            "Time elapsed: 6.55 min\n",
            "Epoch: 048/100 | Batch 000/469 | Gen/Dis Loss: 0.7336/0.8335\n",
            "Epoch: 048/100 | Batch 100/469 | Gen/Dis Loss: 0.8052/0.6823\n",
            "Epoch: 048/100 | Batch 200/469 | Gen/Dis Loss: 0.8003/0.7087\n",
            "Epoch: 048/100 | Batch 300/469 | Gen/Dis Loss: 0.8344/0.6714\n",
            "Epoch: 048/100 | Batch 400/469 | Gen/Dis Loss: 0.8195/0.6967\n",
            "Time elapsed: 6.69 min\n",
            "Epoch: 049/100 | Batch 000/469 | Gen/Dis Loss: 0.7524/0.6256\n",
            "Epoch: 049/100 | Batch 100/469 | Gen/Dis Loss: 0.7625/0.6751\n",
            "Epoch: 049/100 | Batch 200/469 | Gen/Dis Loss: 0.7035/0.8031\n",
            "Epoch: 049/100 | Batch 300/469 | Gen/Dis Loss: 0.8898/0.6491\n",
            "Epoch: 049/100 | Batch 400/469 | Gen/Dis Loss: 0.9092/0.6646\n",
            "Time elapsed: 6.82 min\n",
            "Epoch: 050/100 | Batch 000/469 | Gen/Dis Loss: 0.7531/0.6943\n",
            "Epoch: 050/100 | Batch 100/469 | Gen/Dis Loss: 0.8619/0.6582\n",
            "Epoch: 050/100 | Batch 200/469 | Gen/Dis Loss: 0.9109/0.6789\n",
            "Epoch: 050/100 | Batch 300/469 | Gen/Dis Loss: 0.8820/0.6373\n",
            "Epoch: 050/100 | Batch 400/469 | Gen/Dis Loss: 1.4067/0.4261\n",
            "Time elapsed: 6.96 min\n",
            "Epoch: 051/100 | Batch 000/469 | Gen/Dis Loss: 0.8969/0.5826\n",
            "Epoch: 051/100 | Batch 100/469 | Gen/Dis Loss: 0.7413/0.7176\n",
            "Epoch: 051/100 | Batch 200/469 | Gen/Dis Loss: 0.7961/0.6924\n",
            "Epoch: 051/100 | Batch 300/469 | Gen/Dis Loss: 0.6462/0.9221\n",
            "Epoch: 051/100 | Batch 400/469 | Gen/Dis Loss: 0.6000/0.7932\n",
            "Time elapsed: 7.10 min\n",
            "Epoch: 052/100 | Batch 000/469 | Gen/Dis Loss: 0.8522/0.6296\n",
            "Epoch: 052/100 | Batch 100/469 | Gen/Dis Loss: 0.8109/0.6857\n",
            "Epoch: 052/100 | Batch 200/469 | Gen/Dis Loss: 0.7964/0.6804\n",
            "Epoch: 052/100 | Batch 300/469 | Gen/Dis Loss: 0.8439/0.7691\n",
            "Epoch: 052/100 | Batch 400/469 | Gen/Dis Loss: 0.8233/0.6808\n",
            "Time elapsed: 7.24 min\n",
            "Epoch: 053/100 | Batch 000/469 | Gen/Dis Loss: 0.7940/0.7627\n",
            "Epoch: 053/100 | Batch 100/469 | Gen/Dis Loss: 0.6703/0.8045\n",
            "Epoch: 053/100 | Batch 200/469 | Gen/Dis Loss: 0.8638/0.6731\n",
            "Epoch: 053/100 | Batch 300/469 | Gen/Dis Loss: 0.8777/0.6727\n",
            "Epoch: 053/100 | Batch 400/469 | Gen/Dis Loss: 0.8052/0.6598\n",
            "Time elapsed: 7.38 min\n",
            "Epoch: 054/100 | Batch 000/469 | Gen/Dis Loss: 0.8453/0.6329\n",
            "Epoch: 054/100 | Batch 100/469 | Gen/Dis Loss: 0.7541/0.6957\n",
            "Epoch: 054/100 | Batch 200/469 | Gen/Dis Loss: 0.7840/0.6810\n",
            "Epoch: 054/100 | Batch 300/469 | Gen/Dis Loss: 0.7120/0.6609\n",
            "Epoch: 054/100 | Batch 400/469 | Gen/Dis Loss: 0.6973/0.6620\n",
            "Time elapsed: 7.51 min\n",
            "Epoch: 055/100 | Batch 000/469 | Gen/Dis Loss: 0.7423/0.6727\n",
            "Epoch: 055/100 | Batch 100/469 | Gen/Dis Loss: 0.7439/0.6882\n",
            "Epoch: 055/100 | Batch 200/469 | Gen/Dis Loss: 0.8100/0.7172\n",
            "Epoch: 055/100 | Batch 300/469 | Gen/Dis Loss: 1.0115/0.6511\n",
            "Epoch: 055/100 | Batch 400/469 | Gen/Dis Loss: 0.7071/0.6900\n",
            "Time elapsed: 7.65 min\n",
            "Epoch: 056/100 | Batch 000/469 | Gen/Dis Loss: 0.6927/0.7509\n",
            "Epoch: 056/100 | Batch 100/469 | Gen/Dis Loss: 0.9440/0.7355\n",
            "Epoch: 056/100 | Batch 200/469 | Gen/Dis Loss: 1.0595/0.6563\n",
            "Epoch: 056/100 | Batch 300/469 | Gen/Dis Loss: 0.7302/0.6878\n",
            "Epoch: 056/100 | Batch 400/469 | Gen/Dis Loss: 0.8971/0.6971\n",
            "Time elapsed: 7.79 min\n",
            "Epoch: 057/100 | Batch 000/469 | Gen/Dis Loss: 0.7091/0.7798\n",
            "Epoch: 057/100 | Batch 100/469 | Gen/Dis Loss: 0.7184/0.7213\n",
            "Epoch: 057/100 | Batch 200/469 | Gen/Dis Loss: 0.8614/0.7021\n",
            "Epoch: 057/100 | Batch 300/469 | Gen/Dis Loss: 0.7146/0.7258\n",
            "Epoch: 057/100 | Batch 400/469 | Gen/Dis Loss: 1.0540/0.5805\n",
            "Time elapsed: 7.93 min\n",
            "Epoch: 058/100 | Batch 000/469 | Gen/Dis Loss: 0.8179/0.6144\n",
            "Epoch: 058/100 | Batch 100/469 | Gen/Dis Loss: 0.7269/0.6670\n",
            "Epoch: 058/100 | Batch 200/469 | Gen/Dis Loss: 0.7699/0.7032\n",
            "Epoch: 058/100 | Batch 300/469 | Gen/Dis Loss: 0.8378/0.7080\n",
            "Epoch: 058/100 | Batch 400/469 | Gen/Dis Loss: 0.8202/0.6767\n",
            "Time elapsed: 8.07 min\n",
            "Epoch: 059/100 | Batch 000/469 | Gen/Dis Loss: 0.9153/0.6488\n",
            "Epoch: 059/100 | Batch 100/469 | Gen/Dis Loss: 0.7616/0.6584\n",
            "Epoch: 059/100 | Batch 200/469 | Gen/Dis Loss: 0.7702/0.7050\n",
            "Epoch: 059/100 | Batch 300/469 | Gen/Dis Loss: 0.7648/0.7267\n",
            "Epoch: 059/100 | Batch 400/469 | Gen/Dis Loss: 0.7763/0.7732\n",
            "Time elapsed: 8.21 min\n",
            "Epoch: 060/100 | Batch 000/469 | Gen/Dis Loss: 0.8021/0.6756\n",
            "Epoch: 060/100 | Batch 100/469 | Gen/Dis Loss: 0.8472/0.7098\n",
            "Epoch: 060/100 | Batch 200/469 | Gen/Dis Loss: 0.9437/0.6305\n",
            "Epoch: 060/100 | Batch 300/469 | Gen/Dis Loss: 0.8684/0.6418\n",
            "Epoch: 060/100 | Batch 400/469 | Gen/Dis Loss: 0.8459/0.6322\n",
            "Time elapsed: 8.35 min\n",
            "Epoch: 061/100 | Batch 000/469 | Gen/Dis Loss: 0.7970/0.6631\n",
            "Epoch: 061/100 | Batch 100/469 | Gen/Dis Loss: 0.8374/0.6439\n",
            "Epoch: 061/100 | Batch 200/469 | Gen/Dis Loss: 0.8423/0.6733\n",
            "Epoch: 061/100 | Batch 300/469 | Gen/Dis Loss: 0.7300/0.7608\n",
            "Epoch: 061/100 | Batch 400/469 | Gen/Dis Loss: 0.7553/0.7357\n",
            "Time elapsed: 8.49 min\n",
            "Epoch: 062/100 | Batch 000/469 | Gen/Dis Loss: 0.8977/0.6626\n",
            "Epoch: 062/100 | Batch 100/469 | Gen/Dis Loss: 0.7979/0.6898\n",
            "Epoch: 062/100 | Batch 200/469 | Gen/Dis Loss: 0.7902/0.7078\n",
            "Epoch: 062/100 | Batch 300/469 | Gen/Dis Loss: 0.7358/0.6906\n",
            "Epoch: 062/100 | Batch 400/469 | Gen/Dis Loss: 0.6813/0.7250\n",
            "Time elapsed: 8.63 min\n",
            "Epoch: 063/100 | Batch 000/469 | Gen/Dis Loss: 0.9319/0.6237\n",
            "Epoch: 063/100 | Batch 100/469 | Gen/Dis Loss: 0.5226/0.9338\n",
            "Epoch: 063/100 | Batch 200/469 | Gen/Dis Loss: 0.8849/0.6271\n",
            "Epoch: 063/100 | Batch 300/469 | Gen/Dis Loss: 0.7176/0.7514\n",
            "Epoch: 063/100 | Batch 400/469 | Gen/Dis Loss: 0.9517/0.6219\n",
            "Time elapsed: 8.77 min\n",
            "Epoch: 064/100 | Batch 000/469 | Gen/Dis Loss: 0.7115/0.7077\n",
            "Epoch: 064/100 | Batch 100/469 | Gen/Dis Loss: 0.6827/0.7365\n",
            "Epoch: 064/100 | Batch 200/469 | Gen/Dis Loss: 0.7645/0.6524\n",
            "Epoch: 064/100 | Batch 300/469 | Gen/Dis Loss: 0.6674/0.7636\n",
            "Epoch: 064/100 | Batch 400/469 | Gen/Dis Loss: 0.6861/0.7529\n",
            "Time elapsed: 8.91 min\n",
            "Epoch: 065/100 | Batch 000/469 | Gen/Dis Loss: 0.7531/0.6359\n",
            "Epoch: 065/100 | Batch 100/469 | Gen/Dis Loss: 0.8270/0.6716\n",
            "Epoch: 065/100 | Batch 200/469 | Gen/Dis Loss: 0.7934/0.6474\n",
            "Epoch: 065/100 | Batch 300/469 | Gen/Dis Loss: 0.6998/0.7048\n",
            "Epoch: 065/100 | Batch 400/469 | Gen/Dis Loss: 0.8140/0.6018\n",
            "Time elapsed: 9.05 min\n",
            "Epoch: 066/100 | Batch 000/469 | Gen/Dis Loss: 0.8558/0.6233\n",
            "Epoch: 066/100 | Batch 100/469 | Gen/Dis Loss: 0.8272/0.6392\n",
            "Epoch: 066/100 | Batch 200/469 | Gen/Dis Loss: 0.9193/0.6033\n",
            "Epoch: 066/100 | Batch 300/469 | Gen/Dis Loss: 0.8548/0.6533\n",
            "Epoch: 066/100 | Batch 400/469 | Gen/Dis Loss: 0.7257/0.6792\n",
            "Time elapsed: 9.18 min\n",
            "Epoch: 067/100 | Batch 000/469 | Gen/Dis Loss: 0.6836/0.7346\n",
            "Epoch: 067/100 | Batch 100/469 | Gen/Dis Loss: 0.8726/0.6172\n",
            "Epoch: 067/100 | Batch 200/469 | Gen/Dis Loss: 0.7953/0.7415\n",
            "Epoch: 067/100 | Batch 300/469 | Gen/Dis Loss: 0.7594/0.6256\n",
            "Epoch: 067/100 | Batch 400/469 | Gen/Dis Loss: 0.7490/0.7299\n",
            "Time elapsed: 9.32 min\n",
            "Epoch: 068/100 | Batch 000/469 | Gen/Dis Loss: 0.7781/0.6731\n",
            "Epoch: 068/100 | Batch 100/469 | Gen/Dis Loss: 0.7975/0.7023\n",
            "Epoch: 068/100 | Batch 200/469 | Gen/Dis Loss: 0.7453/0.6494\n",
            "Epoch: 068/100 | Batch 300/469 | Gen/Dis Loss: 0.8314/0.6462\n",
            "Epoch: 068/100 | Batch 400/469 | Gen/Dis Loss: 0.6725/0.6953\n",
            "Time elapsed: 9.46 min\n",
            "Epoch: 069/100 | Batch 000/469 | Gen/Dis Loss: 0.8262/0.6338\n",
            "Epoch: 069/100 | Batch 100/469 | Gen/Dis Loss: 0.8024/0.6349\n",
            "Epoch: 069/100 | Batch 200/469 | Gen/Dis Loss: 0.7970/0.6537\n",
            "Epoch: 069/100 | Batch 300/469 | Gen/Dis Loss: 0.8164/0.6193\n",
            "Epoch: 069/100 | Batch 400/469 | Gen/Dis Loss: 0.6882/0.7260\n",
            "Time elapsed: 9.60 min\n",
            "Epoch: 070/100 | Batch 000/469 | Gen/Dis Loss: 0.7528/0.7044\n",
            "Epoch: 070/100 | Batch 100/469 | Gen/Dis Loss: 0.7034/0.7450\n",
            "Epoch: 070/100 | Batch 200/469 | Gen/Dis Loss: 0.7895/0.6942\n",
            "Epoch: 070/100 | Batch 300/469 | Gen/Dis Loss: 0.8174/0.6836\n",
            "Epoch: 070/100 | Batch 400/469 | Gen/Dis Loss: 0.7768/0.6722\n",
            "Time elapsed: 9.73 min\n",
            "Epoch: 071/100 | Batch 000/469 | Gen/Dis Loss: 0.8115/0.6545\n",
            "Epoch: 071/100 | Batch 100/469 | Gen/Dis Loss: 0.7574/0.6773\n",
            "Epoch: 071/100 | Batch 200/469 | Gen/Dis Loss: 0.7872/0.6413\n",
            "Epoch: 071/100 | Batch 300/469 | Gen/Dis Loss: 0.7578/0.7142\n",
            "Epoch: 071/100 | Batch 400/469 | Gen/Dis Loss: 0.7544/0.6682\n",
            "Time elapsed: 9.88 min\n",
            "Epoch: 072/100 | Batch 000/469 | Gen/Dis Loss: 0.7641/0.6540\n",
            "Epoch: 072/100 | Batch 100/469 | Gen/Dis Loss: 0.8250/0.6356\n",
            "Epoch: 072/100 | Batch 200/469 | Gen/Dis Loss: 0.7912/0.6576\n",
            "Epoch: 072/100 | Batch 300/469 | Gen/Dis Loss: 0.8149/0.6592\n",
            "Epoch: 072/100 | Batch 400/469 | Gen/Dis Loss: 0.7885/0.6850\n",
            "Time elapsed: 10.02 min\n",
            "Epoch: 073/100 | Batch 000/469 | Gen/Dis Loss: 0.7039/0.7157\n",
            "Epoch: 073/100 | Batch 100/469 | Gen/Dis Loss: 0.7782/0.6534\n",
            "Epoch: 073/100 | Batch 200/469 | Gen/Dis Loss: 0.7077/0.6764\n",
            "Epoch: 073/100 | Batch 300/469 | Gen/Dis Loss: 0.9959/0.5134\n",
            "Epoch: 073/100 | Batch 400/469 | Gen/Dis Loss: 1.1106/0.5365\n",
            "Time elapsed: 10.15 min\n",
            "Epoch: 074/100 | Batch 000/469 | Gen/Dis Loss: 0.7952/0.6597\n",
            "Epoch: 074/100 | Batch 100/469 | Gen/Dis Loss: 0.6754/0.7243\n",
            "Epoch: 074/100 | Batch 200/469 | Gen/Dis Loss: 0.7609/0.6822\n",
            "Epoch: 074/100 | Batch 300/469 | Gen/Dis Loss: 0.9130/0.6137\n",
            "Epoch: 074/100 | Batch 400/469 | Gen/Dis Loss: 0.7173/0.6935\n",
            "Time elapsed: 10.29 min\n",
            "Epoch: 075/100 | Batch 000/469 | Gen/Dis Loss: 0.8121/0.6479\n",
            "Epoch: 075/100 | Batch 100/469 | Gen/Dis Loss: 0.7193/0.6955\n",
            "Epoch: 075/100 | Batch 200/469 | Gen/Dis Loss: 0.7593/0.6921\n",
            "Epoch: 075/100 | Batch 300/469 | Gen/Dis Loss: 0.7338/0.6837\n",
            "Epoch: 075/100 | Batch 400/469 | Gen/Dis Loss: 0.8336/0.6254\n",
            "Time elapsed: 10.43 min\n",
            "Epoch: 076/100 | Batch 000/469 | Gen/Dis Loss: 0.7744/0.6559\n",
            "Epoch: 076/100 | Batch 100/469 | Gen/Dis Loss: 0.8514/0.6587\n",
            "Epoch: 076/100 | Batch 200/469 | Gen/Dis Loss: 0.7667/0.6934\n",
            "Epoch: 076/100 | Batch 300/469 | Gen/Dis Loss: 0.7582/0.6562\n",
            "Epoch: 076/100 | Batch 400/469 | Gen/Dis Loss: 0.7240/0.6709\n",
            "Time elapsed: 10.57 min\n",
            "Epoch: 077/100 | Batch 000/469 | Gen/Dis Loss: 0.7173/0.6980\n",
            "Epoch: 077/100 | Batch 100/469 | Gen/Dis Loss: 0.7295/0.6838\n",
            "Epoch: 077/100 | Batch 200/469 | Gen/Dis Loss: 0.7717/0.6623\n",
            "Epoch: 077/100 | Batch 300/469 | Gen/Dis Loss: 0.6566/0.8299\n",
            "Epoch: 077/100 | Batch 400/469 | Gen/Dis Loss: 0.7085/0.7013\n",
            "Time elapsed: 10.71 min\n",
            "Epoch: 078/100 | Batch 000/469 | Gen/Dis Loss: 0.7815/0.6623\n",
            "Epoch: 078/100 | Batch 100/469 | Gen/Dis Loss: 0.7463/0.6597\n",
            "Epoch: 078/100 | Batch 200/469 | Gen/Dis Loss: 0.8164/0.6363\n",
            "Epoch: 078/100 | Batch 300/469 | Gen/Dis Loss: 0.7144/0.7070\n",
            "Epoch: 078/100 | Batch 400/469 | Gen/Dis Loss: 0.8765/0.6623\n",
            "Time elapsed: 10.85 min\n",
            "Epoch: 079/100 | Batch 000/469 | Gen/Dis Loss: 0.8286/0.6594\n",
            "Epoch: 079/100 | Batch 100/469 | Gen/Dis Loss: 0.7580/0.6526\n",
            "Epoch: 079/100 | Batch 200/469 | Gen/Dis Loss: 0.7408/0.6847\n",
            "Epoch: 079/100 | Batch 300/469 | Gen/Dis Loss: 0.7422/0.6834\n",
            "Epoch: 079/100 | Batch 400/469 | Gen/Dis Loss: 0.6938/0.7538\n",
            "Time elapsed: 10.99 min\n",
            "Epoch: 080/100 | Batch 000/469 | Gen/Dis Loss: 0.7723/0.6717\n",
            "Epoch: 080/100 | Batch 100/469 | Gen/Dis Loss: 0.7138/0.6696\n",
            "Epoch: 080/100 | Batch 200/469 | Gen/Dis Loss: 0.6872/0.7171\n",
            "Epoch: 080/100 | Batch 300/469 | Gen/Dis Loss: 0.7788/0.6754\n",
            "Epoch: 080/100 | Batch 400/469 | Gen/Dis Loss: 0.7540/0.6582\n",
            "Time elapsed: 11.13 min\n",
            "Epoch: 081/100 | Batch 000/469 | Gen/Dis Loss: 0.7277/0.6852\n",
            "Epoch: 081/100 | Batch 100/469 | Gen/Dis Loss: 0.7289/0.6954\n",
            "Epoch: 081/100 | Batch 200/469 | Gen/Dis Loss: 0.8457/0.6225\n",
            "Epoch: 081/100 | Batch 300/469 | Gen/Dis Loss: 0.8763/0.6091\n",
            "Epoch: 081/100 | Batch 400/469 | Gen/Dis Loss: 0.7416/0.6745\n",
            "Time elapsed: 11.27 min\n",
            "Epoch: 082/100 | Batch 000/469 | Gen/Dis Loss: 0.6246/0.7537\n",
            "Epoch: 082/100 | Batch 100/469 | Gen/Dis Loss: 0.7490/0.6764\n",
            "Epoch: 082/100 | Batch 200/469 | Gen/Dis Loss: 0.8463/0.6017\n",
            "Epoch: 082/100 | Batch 300/469 | Gen/Dis Loss: 0.8070/0.6328\n",
            "Epoch: 082/100 | Batch 400/469 | Gen/Dis Loss: 0.8170/0.6643\n",
            "Time elapsed: 11.41 min\n",
            "Epoch: 083/100 | Batch 000/469 | Gen/Dis Loss: 0.8007/0.6390\n",
            "Epoch: 083/100 | Batch 100/469 | Gen/Dis Loss: 0.8278/0.6891\n",
            "Epoch: 083/100 | Batch 200/469 | Gen/Dis Loss: 0.8132/0.6286\n",
            "Epoch: 083/100 | Batch 300/469 | Gen/Dis Loss: 0.7514/0.6820\n",
            "Epoch: 083/100 | Batch 400/469 | Gen/Dis Loss: 0.7438/0.6736\n",
            "Time elapsed: 11.55 min\n",
            "Epoch: 084/100 | Batch 000/469 | Gen/Dis Loss: 0.7510/0.6923\n",
            "Epoch: 084/100 | Batch 100/469 | Gen/Dis Loss: 0.7741/0.6764\n",
            "Epoch: 084/100 | Batch 200/469 | Gen/Dis Loss: 0.7766/0.6464\n",
            "Epoch: 084/100 | Batch 300/469 | Gen/Dis Loss: 0.8123/0.6517\n",
            "Epoch: 084/100 | Batch 400/469 | Gen/Dis Loss: 0.7031/0.7151\n",
            "Time elapsed: 11.69 min\n",
            "Epoch: 085/100 | Batch 000/469 | Gen/Dis Loss: 0.7057/0.7024\n",
            "Epoch: 085/100 | Batch 100/469 | Gen/Dis Loss: 0.7556/0.6787\n",
            "Epoch: 085/100 | Batch 200/469 | Gen/Dis Loss: 0.8082/0.6405\n",
            "Epoch: 085/100 | Batch 300/469 | Gen/Dis Loss: 0.7629/0.6672\n",
            "Epoch: 085/100 | Batch 400/469 | Gen/Dis Loss: 0.7379/0.6561\n",
            "Time elapsed: 11.83 min\n",
            "Epoch: 086/100 | Batch 000/469 | Gen/Dis Loss: 0.7326/0.6995\n",
            "Epoch: 086/100 | Batch 100/469 | Gen/Dis Loss: 0.8165/0.6623\n",
            "Epoch: 086/100 | Batch 200/469 | Gen/Dis Loss: 0.8174/0.6931\n",
            "Epoch: 086/100 | Batch 300/469 | Gen/Dis Loss: 0.6737/0.6907\n",
            "Epoch: 086/100 | Batch 400/469 | Gen/Dis Loss: 0.7133/0.7421\n",
            "Time elapsed: 11.97 min\n",
            "Epoch: 087/100 | Batch 000/469 | Gen/Dis Loss: 0.8479/0.6562\n",
            "Epoch: 087/100 | Batch 100/469 | Gen/Dis Loss: 0.7783/0.6559\n",
            "Epoch: 087/100 | Batch 200/469 | Gen/Dis Loss: 0.7640/0.7202\n",
            "Epoch: 087/100 | Batch 300/469 | Gen/Dis Loss: 0.6847/0.6762\n",
            "Epoch: 087/100 | Batch 400/469 | Gen/Dis Loss: 0.7654/0.6642\n",
            "Time elapsed: 12.11 min\n",
            "Epoch: 088/100 | Batch 000/469 | Gen/Dis Loss: 0.6844/0.6619\n",
            "Epoch: 088/100 | Batch 100/469 | Gen/Dis Loss: 0.8425/0.6229\n",
            "Epoch: 088/100 | Batch 200/469 | Gen/Dis Loss: 0.7749/0.6651\n",
            "Epoch: 088/100 | Batch 300/469 | Gen/Dis Loss: 0.8115/0.6462\n",
            "Epoch: 088/100 | Batch 400/469 | Gen/Dis Loss: 0.7901/0.6675\n",
            "Time elapsed: 12.25 min\n",
            "Epoch: 089/100 | Batch 000/469 | Gen/Dis Loss: 0.7983/0.6943\n",
            "Epoch: 089/100 | Batch 100/469 | Gen/Dis Loss: 0.7343/0.6600\n",
            "Epoch: 089/100 | Batch 200/469 | Gen/Dis Loss: 0.6940/0.6673\n",
            "Epoch: 089/100 | Batch 300/469 | Gen/Dis Loss: 0.6970/0.6810\n",
            "Epoch: 089/100 | Batch 400/469 | Gen/Dis Loss: 0.7144/0.6982\n",
            "Time elapsed: 12.39 min\n",
            "Epoch: 090/100 | Batch 000/469 | Gen/Dis Loss: 0.7351/0.6959\n",
            "Epoch: 090/100 | Batch 100/469 | Gen/Dis Loss: 0.7167/0.6939\n",
            "Epoch: 090/100 | Batch 200/469 | Gen/Dis Loss: 0.7188/0.6802\n",
            "Epoch: 090/100 | Batch 300/469 | Gen/Dis Loss: 0.6585/0.7425\n",
            "Epoch: 090/100 | Batch 400/469 | Gen/Dis Loss: 0.7155/0.7017\n",
            "Time elapsed: 12.53 min\n",
            "Epoch: 091/100 | Batch 000/469 | Gen/Dis Loss: 0.7931/0.6531\n",
            "Epoch: 091/100 | Batch 100/469 | Gen/Dis Loss: 0.7928/0.6398\n",
            "Epoch: 091/100 | Batch 200/469 | Gen/Dis Loss: 0.7404/0.6717\n",
            "Epoch: 091/100 | Batch 300/469 | Gen/Dis Loss: 0.8199/0.6337\n",
            "Epoch: 091/100 | Batch 400/469 | Gen/Dis Loss: 0.7111/0.6973\n",
            "Time elapsed: 12.67 min\n",
            "Epoch: 092/100 | Batch 000/469 | Gen/Dis Loss: 0.7227/0.6805\n",
            "Epoch: 092/100 | Batch 100/469 | Gen/Dis Loss: 0.7509/0.6716\n",
            "Epoch: 092/100 | Batch 200/469 | Gen/Dis Loss: 0.7272/0.6850\n",
            "Epoch: 092/100 | Batch 300/469 | Gen/Dis Loss: 0.7887/0.6890\n",
            "Epoch: 092/100 | Batch 400/469 | Gen/Dis Loss: 0.7028/0.6998\n",
            "Time elapsed: 12.80 min\n",
            "Epoch: 093/100 | Batch 000/469 | Gen/Dis Loss: 0.7428/0.6785\n",
            "Epoch: 093/100 | Batch 100/469 | Gen/Dis Loss: 0.7199/0.7105\n",
            "Epoch: 093/100 | Batch 200/469 | Gen/Dis Loss: 0.7110/0.6979\n",
            "Epoch: 093/100 | Batch 300/469 | Gen/Dis Loss: 0.7200/0.6902\n",
            "Epoch: 093/100 | Batch 400/469 | Gen/Dis Loss: 0.6694/0.6806\n",
            "Time elapsed: 12.94 min\n",
            "Epoch: 094/100 | Batch 000/469 | Gen/Dis Loss: 0.7596/0.6808\n",
            "Epoch: 094/100 | Batch 100/469 | Gen/Dis Loss: 0.7583/0.6922\n",
            "Epoch: 094/100 | Batch 200/469 | Gen/Dis Loss: 0.6564/0.7266\n",
            "Epoch: 094/100 | Batch 300/469 | Gen/Dis Loss: 0.7530/0.6713\n",
            "Epoch: 094/100 | Batch 400/469 | Gen/Dis Loss: 0.7503/0.6865\n",
            "Time elapsed: 13.08 min\n",
            "Epoch: 095/100 | Batch 000/469 | Gen/Dis Loss: 0.7543/0.6791\n",
            "Epoch: 095/100 | Batch 100/469 | Gen/Dis Loss: 0.7511/0.6611\n",
            "Epoch: 095/100 | Batch 200/469 | Gen/Dis Loss: 0.7632/0.7016\n",
            "Epoch: 095/100 | Batch 300/469 | Gen/Dis Loss: 0.7755/0.6681\n",
            "Epoch: 095/100 | Batch 400/469 | Gen/Dis Loss: 0.7280/0.6854\n",
            "Time elapsed: 13.22 min\n",
            "Epoch: 096/100 | Batch 000/469 | Gen/Dis Loss: 0.7544/0.6618\n",
            "Epoch: 096/100 | Batch 100/469 | Gen/Dis Loss: 0.7809/0.6707\n",
            "Epoch: 096/100 | Batch 200/469 | Gen/Dis Loss: 0.6960/0.7019\n",
            "Epoch: 096/100 | Batch 300/469 | Gen/Dis Loss: 0.6722/0.7412\n",
            "Epoch: 096/100 | Batch 400/469 | Gen/Dis Loss: 0.7279/0.7089\n",
            "Time elapsed: 13.36 min\n",
            "Epoch: 097/100 | Batch 000/469 | Gen/Dis Loss: 0.7414/0.6815\n",
            "Epoch: 097/100 | Batch 100/469 | Gen/Dis Loss: 0.7170/0.6918\n",
            "Epoch: 097/100 | Batch 200/469 | Gen/Dis Loss: 0.7816/0.6760\n",
            "Epoch: 097/100 | Batch 300/469 | Gen/Dis Loss: 0.7264/0.7023\n",
            "Epoch: 097/100 | Batch 400/469 | Gen/Dis Loss: 0.7220/0.6937\n",
            "Time elapsed: 13.50 min\n",
            "Epoch: 098/100 | Batch 000/469 | Gen/Dis Loss: 0.6592/0.7168\n",
            "Epoch: 098/100 | Batch 100/469 | Gen/Dis Loss: 0.7094/0.7343\n",
            "Epoch: 098/100 | Batch 200/469 | Gen/Dis Loss: 0.7937/0.6784\n",
            "Epoch: 098/100 | Batch 300/469 | Gen/Dis Loss: 0.7440/0.6789\n",
            "Epoch: 098/100 | Batch 400/469 | Gen/Dis Loss: 0.7044/0.6974\n",
            "Time elapsed: 13.64 min\n",
            "Epoch: 099/100 | Batch 000/469 | Gen/Dis Loss: 0.7851/0.6938\n",
            "Epoch: 099/100 | Batch 100/469 | Gen/Dis Loss: 0.7477/0.6889\n",
            "Epoch: 099/100 | Batch 200/469 | Gen/Dis Loss: 0.7366/0.6898\n",
            "Epoch: 099/100 | Batch 300/469 | Gen/Dis Loss: 0.7332/0.6673\n",
            "Epoch: 099/100 | Batch 400/469 | Gen/Dis Loss: 0.7451/0.6857\n",
            "Time elapsed: 13.78 min\n",
            "Epoch: 100/100 | Batch 000/469 | Gen/Dis Loss: 0.7011/0.7198\n",
            "Epoch: 100/100 | Batch 100/469 | Gen/Dis Loss: 0.7282/0.7006\n",
            "Epoch: 100/100 | Batch 200/469 | Gen/Dis Loss: 0.7276/0.6721\n",
            "Epoch: 100/100 | Batch 300/469 | Gen/Dis Loss: 0.7597/0.6616\n",
            "Epoch: 100/100 | Batch 400/469 | Gen/Dis Loss: 0.7539/0.6764\n",
            "Time elapsed: 13.91 min\n",
            "Total Training Time: 13.91 min\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "IZaNugefd1JA",
        "outputId": "7c921881-fec2-4bbb-93e0-3cd3900c664c"
      },
      "source": [
        "model.eval()\n",
        "# Make new images\n",
        "z = torch.zeros((5, LATENT_DIM)).uniform_(-1.0, 1.0).to(device)\n",
        "generated_features = model.generator_forward(z)\n",
        "imgs = generated_features.view(-1, 28, 28)\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(20, 2.5))\n",
        "\n",
        "\n",
        "for i, ax in enumerate(axes):\n",
        "    axes[i].imshow(imgs[i].to(torch.device('cpu')).detach(), cmap='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x180 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}